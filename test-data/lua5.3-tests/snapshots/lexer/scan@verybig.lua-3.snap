---
source: src/main.rs
expression: scanned
input_file: test-data/lua5.3-tests/verybig.lua
---
[
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: String,
        lexeme: "\"testing RK\"",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "foo",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "dummy",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "6",
        computed_lexeme: Some(
            "6",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "7",
        computed_lexeme: Some(
            "7",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "8",
        computed_lexeme: Some(
            "8",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "11",
        computed_lexeme: Some(
            "11",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "12",
        computed_lexeme: Some(
            "12",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "13",
        computed_lexeme: Some(
            "13",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "14",
        computed_lexeme: Some(
            "14",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "17",
        computed_lexeme: Some(
            "17",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "18",
        computed_lexeme: Some(
            "18",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "19",
        computed_lexeme: Some(
            "19",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "20",
        computed_lexeme: Some(
            "20",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "21",
        computed_lexeme: Some(
            "21",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "22",
        computed_lexeme: Some(
            "22",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "23",
        computed_lexeme: Some(
            "23",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "24",
        computed_lexeme: Some(
            "24",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "25",
        computed_lexeme: Some(
            "25",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "26",
        computed_lexeme: Some(
            "26",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "27",
        computed_lexeme: Some(
            "27",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "28",
        computed_lexeme: Some(
            "28",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "29",
        computed_lexeme: Some(
            "29",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "30",
        computed_lexeme: Some(
            "30",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "31",
        computed_lexeme: Some(
            "31",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 11,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Number,
        lexeme: "33",
        computed_lexeme: Some(
            "33",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "34",
        computed_lexeme: Some(
            "34",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "35",
        computed_lexeme: Some(
            "35",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "37",
        computed_lexeme: Some(
            "37",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "38",
        computed_lexeme: Some(
            "38",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "39",
        computed_lexeme: Some(
            "39",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "40",
        computed_lexeme: Some(
            "40",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "41",
        computed_lexeme: Some(
            "41",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "42",
        computed_lexeme: Some(
            "42",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "43",
        computed_lexeme: Some(
            "43",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "44",
        computed_lexeme: Some(
            "44",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "45",
        computed_lexeme: Some(
            "45",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "46",
        computed_lexeme: Some(
            "46",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "47",
        computed_lexeme: Some(
            "47",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "48",
        computed_lexeme: Some(
            "48",
        ),
        line: 12,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "49",
        computed_lexeme: Some(
            "49",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "50",
        computed_lexeme: Some(
            "50",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "51",
        computed_lexeme: Some(
            "51",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "52",
        computed_lexeme: Some(
            "52",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "53",
        computed_lexeme: Some(
            "53",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "54",
        computed_lexeme: Some(
            "54",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "55",
        computed_lexeme: Some(
            "55",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "56",
        computed_lexeme: Some(
            "56",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "57",
        computed_lexeme: Some(
            "57",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "58",
        computed_lexeme: Some(
            "58",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "59",
        computed_lexeme: Some(
            "59",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "60",
        computed_lexeme: Some(
            "60",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "61",
        computed_lexeme: Some(
            "61",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "62",
        computed_lexeme: Some(
            "62",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "63",
        computed_lexeme: Some(
            "63",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "64",
        computed_lexeme: Some(
            "64",
        ),
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "65",
        computed_lexeme: Some(
            "65",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "66",
        computed_lexeme: Some(
            "66",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "67",
        computed_lexeme: Some(
            "67",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "68",
        computed_lexeme: Some(
            "68",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "69",
        computed_lexeme: Some(
            "69",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "70",
        computed_lexeme: Some(
            "70",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "71",
        computed_lexeme: Some(
            "71",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "72",
        computed_lexeme: Some(
            "72",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "73",
        computed_lexeme: Some(
            "73",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "74",
        computed_lexeme: Some(
            "74",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "75",
        computed_lexeme: Some(
            "75",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "76",
        computed_lexeme: Some(
            "76",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "77",
        computed_lexeme: Some(
            "77",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "78",
        computed_lexeme: Some(
            "78",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "79",
        computed_lexeme: Some(
            "79",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "80",
        computed_lexeme: Some(
            "80",
        ),
        line: 14,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "81",
        computed_lexeme: Some(
            "81",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "82",
        computed_lexeme: Some(
            "82",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "83",
        computed_lexeme: Some(
            "83",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "84",
        computed_lexeme: Some(
            "84",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "85",
        computed_lexeme: Some(
            "85",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "86",
        computed_lexeme: Some(
            "86",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "87",
        computed_lexeme: Some(
            "87",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "88",
        computed_lexeme: Some(
            "88",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "89",
        computed_lexeme: Some(
            "89",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "90",
        computed_lexeme: Some(
            "90",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "91",
        computed_lexeme: Some(
            "91",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "92",
        computed_lexeme: Some(
            "92",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "93",
        computed_lexeme: Some(
            "93",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "94",
        computed_lexeme: Some(
            "94",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "95",
        computed_lexeme: Some(
            "95",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "96",
        computed_lexeme: Some(
            "96",
        ),
        line: 15,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Number,
        lexeme: "97",
        computed_lexeme: Some(
            "97",
        ),
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Number,
        lexeme: "98",
        computed_lexeme: Some(
            "98",
        ),
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Number,
        lexeme: "99",
        computed_lexeme: Some(
            "99",
        ),
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Number,
        lexeme: "100",
        computed_lexeme: Some(
            "100",
        ),
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Number,
        lexeme: "101",
        computed_lexeme: Some(
            "101",
        ),
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Number,
        lexeme: "102",
        computed_lexeme: Some(
            "102",
        ),
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Number,
        lexeme: "103",
        computed_lexeme: Some(
            "103",
        ),
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Number,
        lexeme: "104",
        computed_lexeme: Some(
            "104",
        ),
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Number,
        lexeme: "105",
        computed_lexeme: Some(
            "105",
        ),
        line: 17,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Number,
        lexeme: "106",
        computed_lexeme: Some(
            "106",
        ),
        line: 17,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Number,
        lexeme: "107",
        computed_lexeme: Some(
            "107",
        ),
        line: 17,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Number,
        lexeme: "108",
        computed_lexeme: Some(
            "108",
        ),
        line: 17,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Number,
        lexeme: "109",
        computed_lexeme: Some(
            "109",
        ),
        line: 17,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Number,
        lexeme: "110",
        computed_lexeme: Some(
            "110",
        ),
        line: 17,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Number,
        lexeme: "111",
        computed_lexeme: Some(
            "111",
        ),
        line: 17,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Number,
        lexeme: "112",
        computed_lexeme: Some(
            "112",
        ),
        line: 17,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Number,
        lexeme: "113",
        computed_lexeme: Some(
            "113",
        ),
        line: 18,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Number,
        lexeme: "114",
        computed_lexeme: Some(
            "114",
        ),
        line: 18,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Number,
        lexeme: "115",
        computed_lexeme: Some(
            "115",
        ),
        line: 18,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Number,
        lexeme: "116",
        computed_lexeme: Some(
            "116",
        ),
        line: 18,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Number,
        lexeme: "117",
        computed_lexeme: Some(
            "117",
        ),
        line: 18,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Number,
        lexeme: "118",
        computed_lexeme: Some(
            "118",
        ),
        line: 18,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Number,
        lexeme: "119",
        computed_lexeme: Some(
            "119",
        ),
        line: 18,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Number,
        lexeme: "120",
        computed_lexeme: Some(
            "120",
        ),
        line: 18,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Number,
        lexeme: "121",
        computed_lexeme: Some(
            "121",
        ),
        line: 19,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Number,
        lexeme: "122",
        computed_lexeme: Some(
            "122",
        ),
        line: 19,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Number,
        lexeme: "123",
        computed_lexeme: Some(
            "123",
        ),
        line: 19,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Number,
        lexeme: "124",
        computed_lexeme: Some(
            "124",
        ),
        line: 19,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Number,
        lexeme: "125",
        computed_lexeme: Some(
            "125",
        ),
        line: 19,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Number,
        lexeme: "126",
        computed_lexeme: Some(
            "126",
        ),
        line: 19,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Number,
        lexeme: "127",
        computed_lexeme: Some(
            "127",
        ),
        line: 19,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Number,
        lexeme: "128",
        computed_lexeme: Some(
            "128",
        ),
        line: 19,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Number,
        lexeme: "129",
        computed_lexeme: Some(
            "129",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "130",
        computed_lexeme: Some(
            "130",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "131",
        computed_lexeme: Some(
            "131",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "132",
        computed_lexeme: Some(
            "132",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "133",
        computed_lexeme: Some(
            "133",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "134",
        computed_lexeme: Some(
            "134",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "135",
        computed_lexeme: Some(
            "135",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "136",
        computed_lexeme: Some(
            "136",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "137",
        computed_lexeme: Some(
            "137",
        ),
        line: 21,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "138",
        computed_lexeme: Some(
            "138",
        ),
        line: 21,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "139",
        computed_lexeme: Some(
            "139",
        ),
        line: 21,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "140",
        computed_lexeme: Some(
            "140",
        ),
        line: 21,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "141",
        computed_lexeme: Some(
            "141",
        ),
        line: 21,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "142",
        computed_lexeme: Some(
            "142",
        ),
        line: 21,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "143",
        computed_lexeme: Some(
            "143",
        ),
        line: 21,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "144",
        computed_lexeme: Some(
            "144",
        ),
        line: 21,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "145",
        computed_lexeme: Some(
            "145",
        ),
        line: 22,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Number,
        lexeme: "146",
        computed_lexeme: Some(
            "146",
        ),
        line: 22,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Number,
        lexeme: "147",
        computed_lexeme: Some(
            "147",
        ),
        line: 22,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Number,
        lexeme: "148",
        computed_lexeme: Some(
            "148",
        ),
        line: 22,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Number,
        lexeme: "149",
        computed_lexeme: Some(
            "149",
        ),
        line: 22,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Number,
        lexeme: "150",
        computed_lexeme: Some(
            "150",
        ),
        line: 22,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Number,
        lexeme: "151",
        computed_lexeme: Some(
            "151",
        ),
        line: 22,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Number,
        lexeme: "152",
        computed_lexeme: Some(
            "152",
        ),
        line: 22,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Number,
        lexeme: "153",
        computed_lexeme: Some(
            "153",
        ),
        line: 23,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Number,
        lexeme: "154",
        computed_lexeme: Some(
            "154",
        ),
        line: 23,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Number,
        lexeme: "155",
        computed_lexeme: Some(
            "155",
        ),
        line: 23,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Number,
        lexeme: "156",
        computed_lexeme: Some(
            "156",
        ),
        line: 23,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Number,
        lexeme: "157",
        computed_lexeme: Some(
            "157",
        ),
        line: 23,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Number,
        lexeme: "158",
        computed_lexeme: Some(
            "158",
        ),
        line: 23,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Number,
        lexeme: "159",
        computed_lexeme: Some(
            "159",
        ),
        line: 23,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Number,
        lexeme: "160",
        computed_lexeme: Some(
            "160",
        ),
        line: 23,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Number,
        lexeme: "161",
        computed_lexeme: Some(
            "161",
        ),
        line: 24,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Number,
        lexeme: "162",
        computed_lexeme: Some(
            "162",
        ),
        line: 24,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Number,
        lexeme: "163",
        computed_lexeme: Some(
            "163",
        ),
        line: 24,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Number,
        lexeme: "164",
        computed_lexeme: Some(
            "164",
        ),
        line: 24,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Number,
        lexeme: "165",
        computed_lexeme: Some(
            "165",
        ),
        line: 24,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Number,
        lexeme: "166",
        computed_lexeme: Some(
            "166",
        ),
        line: 24,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Number,
        lexeme: "167",
        computed_lexeme: Some(
            "167",
        ),
        line: 24,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Number,
        lexeme: "168",
        computed_lexeme: Some(
            "168",
        ),
        line: 24,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Number,
        lexeme: "169",
        computed_lexeme: Some(
            "169",
        ),
        line: 25,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "170",
        computed_lexeme: Some(
            "170",
        ),
        line: 25,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "171",
        computed_lexeme: Some(
            "171",
        ),
        line: 25,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "172",
        computed_lexeme: Some(
            "172",
        ),
        line: 25,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "173",
        computed_lexeme: Some(
            "173",
        ),
        line: 25,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "174",
        computed_lexeme: Some(
            "174",
        ),
        line: 25,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "175",
        computed_lexeme: Some(
            "175",
        ),
        line: 25,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "176",
        computed_lexeme: Some(
            "176",
        ),
        line: 25,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "177",
        computed_lexeme: Some(
            "177",
        ),
        line: 26,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Number,
        lexeme: "178",
        computed_lexeme: Some(
            "178",
        ),
        line: 26,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Number,
        lexeme: "179",
        computed_lexeme: Some(
            "179",
        ),
        line: 26,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Number,
        lexeme: "180",
        computed_lexeme: Some(
            "180",
        ),
        line: 26,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Number,
        lexeme: "181",
        computed_lexeme: Some(
            "181",
        ),
        line: 26,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Number,
        lexeme: "182",
        computed_lexeme: Some(
            "182",
        ),
        line: 26,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Number,
        lexeme: "183",
        computed_lexeme: Some(
            "183",
        ),
        line: 26,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Number,
        lexeme: "184",
        computed_lexeme: Some(
            "184",
        ),
        line: 26,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Number,
        lexeme: "185",
        computed_lexeme: Some(
            "185",
        ),
        line: 27,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Number,
        lexeme: "186",
        computed_lexeme: Some(
            "186",
        ),
        line: 27,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Number,
        lexeme: "187",
        computed_lexeme: Some(
            "187",
        ),
        line: 27,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Number,
        lexeme: "188",
        computed_lexeme: Some(
            "188",
        ),
        line: 27,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Number,
        lexeme: "189",
        computed_lexeme: Some(
            "189",
        ),
        line: 27,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Number,
        lexeme: "190",
        computed_lexeme: Some(
            "190",
        ),
        line: 27,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Number,
        lexeme: "191",
        computed_lexeme: Some(
            "191",
        ),
        line: 27,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Number,
        lexeme: "192",
        computed_lexeme: Some(
            "192",
        ),
        line: 27,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Number,
        lexeme: "193",
        computed_lexeme: Some(
            "193",
        ),
        line: 28,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Number,
        lexeme: "194",
        computed_lexeme: Some(
            "194",
        ),
        line: 28,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Number,
        lexeme: "195",
        computed_lexeme: Some(
            "195",
        ),
        line: 28,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Number,
        lexeme: "196",
        computed_lexeme: Some(
            "196",
        ),
        line: 28,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Number,
        lexeme: "197",
        computed_lexeme: Some(
            "197",
        ),
        line: 28,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Number,
        lexeme: "198",
        computed_lexeme: Some(
            "198",
        ),
        line: 28,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Number,
        lexeme: "199",
        computed_lexeme: Some(
            "199",
        ),
        line: 28,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Number,
        lexeme: "200",
        computed_lexeme: Some(
            "200",
        ),
        line: 28,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Number,
        lexeme: "201",
        computed_lexeme: Some(
            "201",
        ),
        line: 29,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Number,
        lexeme: "202",
        computed_lexeme: Some(
            "202",
        ),
        line: 29,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Number,
        lexeme: "203",
        computed_lexeme: Some(
            "203",
        ),
        line: 29,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Number,
        lexeme: "204",
        computed_lexeme: Some(
            "204",
        ),
        line: 29,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Number,
        lexeme: "205",
        computed_lexeme: Some(
            "205",
        ),
        line: 29,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Number,
        lexeme: "206",
        computed_lexeme: Some(
            "206",
        ),
        line: 29,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Number,
        lexeme: "207",
        computed_lexeme: Some(
            "207",
        ),
        line: 29,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Number,
        lexeme: "208",
        computed_lexeme: Some(
            "208",
        ),
        line: 29,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Number,
        lexeme: "209",
        computed_lexeme: Some(
            "209",
        ),
        line: 30,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Number,
        lexeme: "210",
        computed_lexeme: Some(
            "210",
        ),
        line: 30,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Number,
        lexeme: "211",
        computed_lexeme: Some(
            "211",
        ),
        line: 30,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Number,
        lexeme: "212",
        computed_lexeme: Some(
            "212",
        ),
        line: 30,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Number,
        lexeme: "213",
        computed_lexeme: Some(
            "213",
        ),
        line: 30,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Number,
        lexeme: "214",
        computed_lexeme: Some(
            "214",
        ),
        line: 30,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Number,
        lexeme: "215",
        computed_lexeme: Some(
            "215",
        ),
        line: 30,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Number,
        lexeme: "216",
        computed_lexeme: Some(
            "216",
        ),
        line: 30,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Number,
        lexeme: "217",
        computed_lexeme: Some(
            "217",
        ),
        line: 31,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Number,
        lexeme: "218",
        computed_lexeme: Some(
            "218",
        ),
        line: 31,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Number,
        lexeme: "219",
        computed_lexeme: Some(
            "219",
        ),
        line: 31,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Number,
        lexeme: "220",
        computed_lexeme: Some(
            "220",
        ),
        line: 31,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Number,
        lexeme: "221",
        computed_lexeme: Some(
            "221",
        ),
        line: 31,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Number,
        lexeme: "222",
        computed_lexeme: Some(
            "222",
        ),
        line: 31,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Number,
        lexeme: "223",
        computed_lexeme: Some(
            "223",
        ),
        line: 31,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Number,
        lexeme: "224",
        computed_lexeme: Some(
            "224",
        ),
        line: 31,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Number,
        lexeme: "225",
        computed_lexeme: Some(
            "225",
        ),
        line: 32,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Number,
        lexeme: "226",
        computed_lexeme: Some(
            "226",
        ),
        line: 32,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Number,
        lexeme: "227",
        computed_lexeme: Some(
            "227",
        ),
        line: 32,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Number,
        lexeme: "228",
        computed_lexeme: Some(
            "228",
        ),
        line: 32,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Number,
        lexeme: "229",
        computed_lexeme: Some(
            "229",
        ),
        line: 32,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Number,
        lexeme: "230",
        computed_lexeme: Some(
            "230",
        ),
        line: 32,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Number,
        lexeme: "231",
        computed_lexeme: Some(
            "231",
        ),
        line: 32,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Number,
        lexeme: "232",
        computed_lexeme: Some(
            "232",
        ),
        line: 32,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Number,
        lexeme: "233",
        computed_lexeme: Some(
            "233",
        ),
        line: 33,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Number,
        lexeme: "234",
        computed_lexeme: Some(
            "234",
        ),
        line: 33,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Number,
        lexeme: "235",
        computed_lexeme: Some(
            "235",
        ),
        line: 33,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Number,
        lexeme: "236",
        computed_lexeme: Some(
            "236",
        ),
        line: 33,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Number,
        lexeme: "237",
        computed_lexeme: Some(
            "237",
        ),
        line: 33,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Number,
        lexeme: "238",
        computed_lexeme: Some(
            "238",
        ),
        line: 33,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Number,
        lexeme: "239",
        computed_lexeme: Some(
            "239",
        ),
        line: 33,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Number,
        lexeme: "240",
        computed_lexeme: Some(
            "240",
        ),
        line: 33,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Number,
        lexeme: "241",
        computed_lexeme: Some(
            "241",
        ),
        line: 34,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Number,
        lexeme: "242",
        computed_lexeme: Some(
            "242",
        ),
        line: 34,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Number,
        lexeme: "243",
        computed_lexeme: Some(
            "243",
        ),
        line: 34,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Number,
        lexeme: "244",
        computed_lexeme: Some(
            "244",
        ),
        line: 34,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Number,
        lexeme: "245",
        computed_lexeme: Some(
            "245",
        ),
        line: 34,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Number,
        lexeme: "246",
        computed_lexeme: Some(
            "246",
        ),
        line: 34,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Number,
        lexeme: "247",
        computed_lexeme: Some(
            "247",
        ),
        line: 34,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Number,
        lexeme: "248",
        computed_lexeme: Some(
            "248",
        ),
        line: 34,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Number,
        lexeme: "249",
        computed_lexeme: Some(
            "249",
        ),
        line: 35,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Number,
        lexeme: "250",
        computed_lexeme: Some(
            "250",
        ),
        line: 35,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Number,
        lexeme: "251",
        computed_lexeme: Some(
            "251",
        ),
        line: 35,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Number,
        lexeme: "252",
        computed_lexeme: Some(
            "252",
        ),
        line: 35,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Number,
        lexeme: "253",
        computed_lexeme: Some(
            "253",
        ),
        line: 35,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Number,
        lexeme: "254",
        computed_lexeme: Some(
            "254",
        ),
        line: 35,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Number,
        lexeme: "255",
        computed_lexeme: Some(
            "255",
        ),
        line: 35,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Number,
        lexeme: "256",
        computed_lexeme: Some(
            "256",
        ),
        line: 35,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Number,
        lexeme: "24.5",
        computed_lexeme: Some(
            "24.5",
        ),
        line: 37,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Number,
        lexeme: "0.6",
        computed_lexeme: Some(
            "0.6",
        ),
        line: 37,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Number,
        lexeme: "25.1",
        computed_lexeme: Some(
            "25.1",
        ),
        line: 37,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "foo",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "self",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "self",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 38,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Identifier,
        lexeme: "foo",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Number,
        lexeme: "1.5",
        computed_lexeme: Some(
            "1.5",
        ),
        line: 40,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Number,
        lexeme: "11.5",
        computed_lexeme: Some(
            "11.5",
        ),
        line: 40,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "foo",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 41,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Number,
        lexeme: "10.5",
        computed_lexeme: Some(
            "10.5",
        ),
        line: 41,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Number,
        lexeme: "24.3",
        computed_lexeme: Some(
            "24.3",
        ),
        line: 42,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Number,
        lexeme: "24.3",
        computed_lexeme: Some(
            "24.3",
        ),
        line: 42,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 43,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Identifier,
        lexeme: "foo",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: Identifier,
        lexeme: "foo",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Identifier,
        lexeme: "_soft",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 50,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: String,
        lexeme: "\"testing large programs (>64k)\"",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[$\n\nlocal a,b\n\nb = {$1$\n  b30009 = 65534,\n  b30010 = 65535,\n  b30011 = 65536,\n  b30012 = 65537,\n  b30013 = 16777214,\n  b30014 = 16777215,\n  b30015 = 16777216,\n  b30016 = 16777217,\n  b30017 = 0x7fffff,\n  b30018 = -0x7fffff,\n  b30019 = 0x1ffffff,\n  b30020 = -0x1ffffd,\n  b30021 = -65534,\n  b30022 = -65535,\n  b30023 = -65536,\n  b30024 = -0xffffff,\n  b30025 = 15012.5,\n  $2$\n};\n\nassert(b.a50008 == 25004 and b[\"a11\"] == -5.5)\nassert(b.a33007 == -16503.5 and b.a50009 == -25004.5)\nassert(b[\"b\"..30024] == -0xffffff)\n\nfunction b:xxx (a,b) return a+b end\nassert(b:xxx(10, 12) == 22)   -- pushself with non-constant index\nb.xxx = nil\n\ns = 0; n=0\nfor a,b in pairs(b) do s=s+b; n=n+1 end\n-- with 32-bit floats, exact value of 's' depends on summation order\nassert(81800000.0 < s and s < 81860000 and n == 70001)\n\na = nil; b = nil\nprint'+'\n\nfunction f(x) b=x end\n\na = f{$3$} or 10\n\nassert(a==10)\nassert(b[1] == \"a10\" and b[2] == 5 and b[#b-1] == \"a50009\")\n\n\nfunction xxxx (x) return b[x] end\n\nassert(xxxx(3) == \"a11\")\n\na = nil; b=nil\nxxxx = nil\n\nreturn 10\n\n]]",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Identifier,
        lexeme: "sig",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 118,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 118,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: String,
        lexeme: "''",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: String,
        lexeme: "'-'",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Identifier,
        lexeme: "F",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 123,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: Number,
        lexeme: "50009",
        computed_lexeme: Some(
            "50009",
        ),
        line: 123,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: String,
        lexeme: "' = '",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "sig",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 124,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 124,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 124,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: String,
        lexeme: "',\\n'",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Number,
        lexeme: "30026",
        computed_lexeme: Some(
            "30026",
        ),
        line: 129,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Number,
        lexeme: "50009",
        computed_lexeme: Some(
            "50009",
        ),
        line: 129,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: String,
        lexeme: "' = '",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "sig",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Number,
        lexeme: "15013",
        computed_lexeme: Some(
            "15013",
        ),
        line: 130,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Number,
        lexeme: "30026",
        computed_lexeme: Some(
            "30026",
        ),
        line: 130,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 130,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: String,
        lexeme: "',\\n'",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 132,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 132,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 135,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Number,
        lexeme: "50009",
        computed_lexeme: Some(
            "50009",
        ),
        line: 135,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: String,
        lexeme: "'\"a'",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: String,
        lexeme: "'\", '",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "sig",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 136,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 136,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 136,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: String,
        lexeme: "',\\n'",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "tmpname",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "gmatch",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: String,
        lexeme: "\"$([^$]+)\"",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "F",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Identifier,
        lexeme: "result",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: String,
        lexeme: "'OK'",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "result",
        computed_lexeme: None,
        line: 151,
    },
]
