---
source: src/main.rs
expression: scanned
input_file: test-data/lua5.4-tests/all.lua
---
[
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "version",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: String,
        lexeme: "\"Lua 5.4\"",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "_VERSION",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "version",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "stderr",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: String,
        lexeme: "\"This test suite is for \"",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "version",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: String,
        lexeme: "\", not for \"",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "_VERSION",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: String,
        lexeme: "\"\\nExiting tests\"",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "ARG",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "arg",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "_soft",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Identifier,
        lexeme: "rawget",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: String,
        lexeme: "\"_soft\"",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: False,
        lexeme: "false",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Identifier,
        lexeme: "_port",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Identifier,
        lexeme: "rawget",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: String,
        lexeme: "\"_port\"",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: False,
        lexeme: "false",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Identifier,
        lexeme: "_nomsg",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "rawget",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: String,
        lexeme: "\"_nomsg\"",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: False,
        lexeme: "false",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Identifier,
        lexeme: "usertests",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Identifier,
        lexeme: "rawget",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: String,
        lexeme: "\"_U\"",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Identifier,
        lexeme: "usertests",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Identifier,
        lexeme: "_soft",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Identifier,
        lexeme: "_port",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Identifier,
        lexeme: "_nomsg",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "debug",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "usertests",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Identifier,
        lexeme: "rawget",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: String,
        lexeme: "\"T\"",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\\tStarting Tests\"",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Identifier,
        lexeme: "random_x",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Identifier,
        lexeme: "random_y",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Identifier,
        lexeme: "randomseed",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: String,
        lexeme: "\"random seeds: %d, %d\"",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Identifier,
        lexeme: "random_x",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Identifier,
        lexeme: "random_y",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: String,
        lexeme: "\"current path:\\n****\"",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Identifier,
        lexeme: "package",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Identifier,
        lexeme: "path",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: String,
        lexeme: "\"****\\n\"",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Identifier,
        lexeme: "initclock",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Identifier,
        lexeme: "clock",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Identifier,
        lexeme: "lastclock",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Identifier,
        lexeme: "initclock",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "walltime",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Identifier,
        lexeme: "msgs",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "Message",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "_nomsg",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Identifier,
        lexeme: "msgs",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Hash,
        lexeme: "#",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "msgs",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 78,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "sub",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 78,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 78,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "setlocale",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: String,
        lexeme: "\"C\"",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "unpack",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "table",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "unpack",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "F",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Identifier,
        lexeme: "round",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Number,
        lexeme: "0.04999",
        computed_lexeme: Some(
            "0.04999",
        ),
        line: 90,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: String,
        lexeme: "\"%.1f\"",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Number,
        lexeme: "1000",
        computed_lexeme: Some(
            "1000",
        ),
        line: 93,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Number,
        lexeme: "1000",
        computed_lexeme: Some(
            "1000",
        ),
        line: 95,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Number,
        lexeme: "1000",
        computed_lexeme: Some(
            "1000",
        ),
        line: 96,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "round",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: String,
        lexeme: "\"K\"",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "round",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Number,
        lexeme: "1000",
        computed_lexeme: Some(
            "1000",
        ),
        line: 98,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: String,
        lexeme: "\"M\"",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "Cstacklevel",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Identifier,
        lexeme: "showmem",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "showmem",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: String,
        lexeme: "\"count\"",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Number,
        lexeme: "1024",
        computed_lexeme: Some(
            "1024",
        ),
        line: 109,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: String,
        lexeme: "\"    ---- total memory: %s, max memory: %s ----\\n\"",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "F",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "F",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Identifier,
        lexeme: "Cstacklevel",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 114,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Identifier,
        lexeme: "showmem",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Identifier,
        lexeme: "checkmemory",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "total",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "numblocks",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "maxmem",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "totalmem",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: String,
        lexeme: "\"count\"",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: String,
        lexeme: "\"\\n    ---- total memory: %s (%.0fK), max use: %s,  blocks: %d\\n\"",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Identifier,
        lexeme: "F",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Identifier,
        lexeme: "total",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Identifier,
        lexeme: "F",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Identifier,
        lexeme: "maxmem",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Identifier,
        lexeme: "numblocks",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: String,
        lexeme: "\"\\t(strings:  %d, tables: %d, functions: %d, \"",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\\tudata: %d, threads: %d)\"",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "totalmem",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: String,
        lexeme: "\"string\"",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "totalmem",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: String,
        lexeme: "\"table\"",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "totalmem",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: String,
        lexeme: "\"function\"",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Identifier,
        lexeme: "totalmem",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: String,
        lexeme: "\"userdata\"",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Identifier,
        lexeme: "totalmem",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: String,
        lexeme: "\"thread\"",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Identifier,
        lexeme: "Cstacklevel",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "ncalls",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "stacklevel",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "ncalls",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 132,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "Cstack",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "Cstacklevel",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "report",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: String,
        lexeme: "\"\\n***** FILE '\"",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: String,
        lexeme: "\"'*****\"",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Identifier,
        lexeme: "olddofile",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "strip",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "showmem",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "clock",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: String,
        lexeme: "\"time: %g (+%g)\"",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "initclock",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "lastclock",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "lastclock",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Identifier,
        lexeme: "report",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "loadfile",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "dump",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "strip",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: String,
        lexeme: "'main.lua'",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Identifier,
        lexeme: "require",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: String,
        lexeme: "\"tracegc\"",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Identifier,
        lexeme: "start",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Identifier,
        lexeme: "report",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: String,
        lexeme: "\"gc.lua\"",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "loadfile",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: String,
        lexeme: "'gc.lua'",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: String,
        lexeme: "'db.lua'",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: String,
        lexeme: "'calls.lua'",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "deep",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "deep",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "olddofile",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: String,
        lexeme: "'strings.lua'",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Identifier,
        lexeme: "olddofile",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: String,
        lexeme: "'literals.lua'",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: String,
        lexeme: "'tpack.lua'",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: String,
        lexeme: "'attrib.lua'",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Number,
        lexeme: "27",
        computed_lexeme: Some(
            "27",
        ),
        line: 169,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: String,
        lexeme: "'gengc.lua'",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: String,
        lexeme: "'locals.lua'",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 171,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: String,
        lexeme: "'constructs.lua'",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: String,
        lexeme: "'code.lua'",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Identifier,
        lexeme: "_soft",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Identifier,
        lexeme: "report",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: String,
        lexeme: "'big.lua'",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "coroutine",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "wrap",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "loadfile",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: String,
        lexeme: "'big.lua'",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 179,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: String,
        lexeme: "'cstack.lua'",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: String,
        lexeme: "'nextvar.lua'",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: String,
        lexeme: "'pm.lua'",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: String,
        lexeme: "'utf8.lua'",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: String,
        lexeme: "'api.lua'",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: String,
        lexeme: "'events.lua'",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Number,
        lexeme: "12",
        computed_lexeme: Some(
            "12",
        ),
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: String,
        lexeme: "'vararg.lua'",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: String,
        lexeme: "'closure.lua'",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: String,
        lexeme: "'coroutine.lua'",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: String,
        lexeme: "'goto.lua'",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: String,
        lexeme: "'errors.lua'",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: String,
        lexeme: "'math.lua'",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: String,
        lexeme: "'sort.lua'",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: String,
        lexeme: "'bitwise.lua'",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: String,
        lexeme: "'verybig.lua'",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 194,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "dofile",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: String,
        lexeme: "'files.lua'",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Hash,
        lexeme: "#",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "msgs",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 197,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "table",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "concat",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "msgs",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: String,
        lexeme: "\"\\n  \"",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: String,
        lexeme: "\"#tests not performed:\\n  \"",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\"",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: String,
        lexeme: "\"(there should be two warnings now)\"",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: String,
        lexeme: "\"@on\"",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: String,
        lexeme: "\"#This is \"",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: String,
        lexeme: "\"an expected\"",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: String,
        lexeme: "\" warning\"",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: String,
        lexeme: "\"@off\"",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: String,
        lexeme: "\"******** THIS WARNING SHOULD NOT APPEAR **********\"",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: String,
        lexeme: "\"******** THIS WARNING ALSO SHOULD NOT APPEAR **********\"",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: String,
        lexeme: "\"@on\"",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: String,
        lexeme: "\"#This is\"",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: String,
        lexeme: "\" another one\"",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Identifier,
        lexeme: "debug",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Identifier,
        lexeme: "debug",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Identifier,
        lexeme: "require",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: String,
        lexeme: "\"debug\"",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: String,
        lexeme: "\"%d-bit integers, %d-bit floats\"",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "packsize",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: String,
        lexeme: "\"j\"",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Number,
        lexeme: "8",
        computed_lexeme: Some(
            "8",
        ),
        line: 217,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "packsize",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: String,
        lexeme: "\"n\"",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Number,
        lexeme: "8",
        computed_lexeme: Some(
            "8",
        ),
        line: 217,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "debug",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "sethook",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: String,
        lexeme: "'string'",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: String,
        lexeme: "\"cr\"",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Identifier,
        lexeme: "showmem",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Identifier,
        lexeme: "showmem",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Identifier,
        lexeme: "Cstack",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Identifier,
        lexeme: "Cstacklevel",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: String,
        lexeme: "\"should be at the same C-stack level it was when started the tests\"",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "showmem",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "clock",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "difftime",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "showmem",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "clock",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "difftime",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "fname",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: String,
        lexeme: "\"time-debug.txt\"",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: String,
        lexeme: "\"time.txt\"",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "lasttime",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "usertests",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "fname",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "lasttime",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "lasttime",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: String,
        lexeme: "'cleaning all!!!!'",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: Identifier,
        lexeme: "pairs",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Identifier,
        lexeme: "___Glob",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 253,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Identifier,
        lexeme: "tostring",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 253,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Identifier,
        lexeme: "undef",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "showmem",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "clocktime",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "clock",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "initclock",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "walltime",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Identifier,
        lexeme: "difftime",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Identifier,
        lexeme: "walltime",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\\ntotal time: %.2fs (wall time: %gs)\\n\"",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Identifier,
        lexeme: "clocktime",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Identifier,
        lexeme: "walltime",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Identifier,
        lexeme: "usertests",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Identifier,
        lexeme: "lasttime",
        computed_lexeme: None,
        line: 272,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 272,
    },
    Token {
        kind: Identifier,
        lexeme: "lasttime",
        computed_lexeme: None,
        line: 272,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 272,
    },
    Token {
        kind: Identifier,
        lexeme: "clocktime",
        computed_lexeme: None,
        line: 272,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Identifier,
        lexeme: "diff",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Identifier,
        lexeme: "clocktime",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Identifier,
        lexeme: "lasttime",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Identifier,
        lexeme: "lasttime",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Identifier,
        lexeme: "tolerance",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Number,
        lexeme: "0.05",
        computed_lexeme: Some(
            "0.05",
        ),
        line: 275,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Identifier,
        lexeme: "diff",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Identifier,
        lexeme: "tolerance",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Identifier,
        lexeme: "diff",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Identifier,
        lexeme: "tolerance",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Identifier,
        lexeme: "warn",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: String,
        lexeme: "\"#time difference from previous test: %+.1f%%\"",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: Identifier,
        lexeme: "diff",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Number,
        lexeme: "100",
        computed_lexeme: Some(
            "100",
        ),
        line: 278,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Identifier,
        lexeme: "fname",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: String,
        lexeme: "\"w\"",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Identifier,
        lexeme: "clocktime",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: String,
        lexeme: "\"final OK !!!\"",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 283,
    },
]
