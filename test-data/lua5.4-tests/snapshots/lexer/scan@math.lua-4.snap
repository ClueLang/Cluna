---
source: src/main.rs
expression: scanned
input_file: test-data/lua5.4-tests/math.lua
---
[
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: String,
        lexeme: "\"testing numbers and math lib\"",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "mininteger",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "maxinteger",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 9,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 9,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 10,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 10,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 12,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 12,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 13,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Number,
        lexeme: "24",
        computed_lexeme: Some(
            "24",
        ),
        line: 16,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 18,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: While,
        lexeme: "while",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 19,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 20,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 21,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "isNaN",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Identifier,
        lexeme: "isNaN",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 29,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 29,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Identifier,
        lexeme: "isNaN",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 30,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 30,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 34,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 35,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 35,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: String,
        lexeme: "\"%d-bit integers, %d-bit (mantissa) floats\"",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 41,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: String,
        lexeme: "\"integer\"",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 41,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: String,
        lexeme: "\"float\"",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: String,
        lexeme: "\"10\"",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: Identifier,
        lexeme: "msg",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: TripleDot,
        lexeme: "...",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "err",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: TripleDot,
        lexeme: "...",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: Identifier,
        lexeme: "find",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: Identifier,
        lexeme: "err",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: Identifier,
        lexeme: "msg",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Identifier,
        lexeme: "msgf2i",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: String,
        lexeme: "\"number.* has no integer representation\"",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "limit",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "limit",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Number,
        lexeme: "50",
        computed_lexeme: Some(
            "50",
        ),
        line: 55,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Identifier,
        lexeme: "limit",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Number,
        lexeme: "1E-11",
        computed_lexeme: Some(
            "1e-11",
        ),
        line: 56,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 57,
    },
    Token {
        kind: Identifier,
        lexeme: "limit",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Number,
        lexeme: "1E-5",
        computed_lexeme: Some(
            "1e-5",
        ),
        line: 58,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Identifier,
        lexeme: "abs",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Identifier,
        lexeme: "limit",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "0e12",
        computed_lexeme: Some(
            "0e12",
        ),
        line: 71,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 71,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: ".0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 71,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 71,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "0.",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 71,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 71,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: ".2e2",
        computed_lexeme: Some(
            "0.2e2",
        ),
        line: 71,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "20",
        computed_lexeme: Some(
            "20",
        ),
        line: 71,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "2.E-1",
        computed_lexeme: Some(
            "2.0e-1",
        ),
        line: 71,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "0.2",
        computed_lexeme: Some(
            "0.2",
        ),
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: String,
        lexeme: "\"2\"",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: String,
        lexeme: "\" 3e0 \"",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: String,
        lexeme: "\" 10  \"",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 75,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 75,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: String,
        lexeme: "\"2\"",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 75,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: String,
        lexeme: "\"10\"",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 75,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: String,
        lexeme: "'string'",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: String,
        lexeme: "'string'",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: String,
        lexeme: "'string'",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: String,
        lexeme: "\"2\"",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: String,
        lexeme: "\" 3e0 \"",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: String,
        lexeme: "\" 10  \"",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: String,
        lexeme: "\"  10 \"",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 78,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Number,
        lexeme: "08",
        computed_lexeme: Some(
            "08",
        ),
        line: 78,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 79,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 80,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 80,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 84,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 85,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 86,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 86,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Number,
        lexeme: "20",
        computed_lexeme: Some(
            "20",
        ),
        line: 86,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Number,
        lexeme: "30",
        computed_lexeme: Some(
            "30",
        ),
        line: 86,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Number,
        lexeme: "40",
        computed_lexeme: Some(
            "40",
        ),
        line: 86,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Number,
        lexeme: "50",
        computed_lexeme: Some(
            "50",
        ),
        line: 86,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 87,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 87,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 87,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "modf",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Number,
        lexeme: "3.5",
        computed_lexeme: Some(
            "3.5",
        ),
        line: 91,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: Number,
        lexeme: "3.0",
        computed_lexeme: Some(
            "3.0",
        ),
        line: 92,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 92,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "modf",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Number,
        lexeme: "2.5",
        computed_lexeme: Some(
            "2.5",
        ),
        line: 93,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 94,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 94,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "modf",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Number,
        lexeme: "3e23",
        computed_lexeme: Some(
            "3e23",
        ),
        line: 95,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Number,
        lexeme: "3e23",
        computed_lexeme: Some(
            "3e23",
        ),
        line: 96,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 96,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Identifier,
        lexeme: "modf",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Number,
        lexeme: "3e35",
        computed_lexeme: Some(
            "3e35",
        ),
        line: 97,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Number,
        lexeme: "3e35",
        computed_lexeme: Some(
            "3e35",
        ),
        line: 98,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 98,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "modf",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 99,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 99,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 100,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 100,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 100,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Identifier,
        lexeme: "modf",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 101,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 101,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 102,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 102,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 102,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "modf",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 103,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 103,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Identifier,
        lexeme: "isNaN",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Identifier,
        lexeme: "isNaN",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Identifier,
        lexeme: "modf",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 105,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 106,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 106,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "modf",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 108,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Number,
        lexeme: "10e30",
        computed_lexeme: Some(
            "10e30",
        ),
        line: 111,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Number,
        lexeme: "10e30",
        computed_lexeme: Some(
            "10e30",
        ),
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 116,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 117,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 118,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 119,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "pairs",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 125,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 125,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Identifier,
        lexeme: "pairs",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 126,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 126,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 126,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Identifier,
        lexeme: "ti",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Identifier,
        lexeme: "pairs",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 127,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 127,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Identifier,
        lexeme: "tj",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Identifier,
        lexeme: "pairs",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 128,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 128,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Identifier,
        lexeme: "ti",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "tj",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 132,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 137,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 137,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 137,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 137,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 138,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 138,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 138,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 138,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Number,
        lexeme: "3.5",
        computed_lexeme: Some(
            "3.5",
        ),
        line: 139,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Number,
        lexeme: "1.5",
        computed_lexeme: Some(
            "1.5",
        ),
        line: 139,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 139,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: Number,
        lexeme: "3.5",
        computed_lexeme: Some(
            "3.5",
        ),
        line: 140,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: Number,
        lexeme: "1.5",
        computed_lexeme: Some(
            "1.5",
        ),
        line: 140,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: Number,
        lexeme: "3.0",
        computed_lexeme: Some(
            "3.0",
        ),
        line: 140,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 144,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 144,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 144,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 144,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 145,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 145,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 145,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 145,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Number,
        lexeme: "3.5",
        computed_lexeme: Some(
            "3.5",
        ),
        line: 146,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 146,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Number,
        lexeme: "3.0",
        computed_lexeme: Some(
            "3.0",
        ),
        line: 146,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 147,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Number,
        lexeme: "4.0",
        computed_lexeme: Some(
            "4.0",
        ),
        line: 147,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Number,
        lexeme: "3.5",
        computed_lexeme: Some(
            "3.5",
        ),
        line: 149,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Number,
        lexeme: "1.5",
        computed_lexeme: Some(
            "1.5",
        ),
        line: 149,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 149,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Number,
        lexeme: "3.5",
        computed_lexeme: Some(
            "3.5",
        ),
        line: 150,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Number,
        lexeme: "1.5",
        computed_lexeme: Some(
            "1.5",
        ),
        line: 150,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Number,
        lexeme: "3.0",
        computed_lexeme: Some(
            "3.0",
        ),
        line: 150,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 153,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 154,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 155,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 155,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 156,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 156,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 157,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 158,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 159,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 159,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 160,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 160,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 161,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 163,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 164,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 164,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 164,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 165,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 170,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 170,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 170,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 170,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 170,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 171,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 171,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 171,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 171,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 171,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 172,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 172,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 173,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 173,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Identifier,
        lexeme: "_port",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 175,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 175,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 176,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 179,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 184,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 184,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 185,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 185,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 185,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 186,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 186,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 186,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 188,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 188,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 188,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 188,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 190,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 191,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 191,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 192,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 192,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 193,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 195,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 195,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 195,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 195,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 196,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 197,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 197,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 197,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 201,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 201,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 201,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Number,
        lexeme: "0.9",
        computed_lexeme: Some(
            "0.9",
        ),
        line: 201,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 202,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 202,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 202,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Number,
        lexeme: "0.9",
        computed_lexeme: Some(
            "0.9",
        ),
        line: 202,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 203,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Number,
        lexeme: "0.9",
        computed_lexeme: Some(
            "0.9",
        ),
        line: 203,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 203,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 203,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 204,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 204,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 204,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 204,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 205,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Number,
        lexeme: "0.9",
        computed_lexeme: Some(
            "0.9",
        ),
        line: 205,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 205,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 205,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 206,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Number,
        lexeme: "0.9",
        computed_lexeme: Some(
            "0.9",
        ),
        line: 206,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 206,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 206,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 207,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 207,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 208,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 208,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 209,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 209,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 210,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 211,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 212,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Identifier,
        lexeme: "fmaxi1",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 215,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 215,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "fmaxi1",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "fmaxi1",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "fmaxi1",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 219,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 219,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 220,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 220,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 221,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: String,
        lexeme: "\"testing order (floats cannot represent all integers)\"",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Identifier,
        lexeme: "fmax",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 225,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Identifier,
        lexeme: "ifmax",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Identifier,
        lexeme: "fmax",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: BitOr,
        lexeme: "|",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 226,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "fmax",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "ifmax",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 227,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "fmax",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 228,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "ifmax",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Identifier,
        lexeme: "fmax",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 229,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Identifier,
        lexeme: "ifmax",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "fmax",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "ifmax",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 230,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "fmax",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "ifmax",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 231,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "fmax",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "ifmax",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 232,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "fmax",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 234,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 234,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "ifmax",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 234,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "fmax",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 235,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 235,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "ifmax",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 235,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 237,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 238,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 239,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 240,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: String,
        lexeme: "\"testing order (floats can represent all integers)\"",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 243,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 244,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 245,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 246,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 247,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 248,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 249,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 250,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 251,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 252,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 253,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 254,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 255,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 257,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 258,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 259,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 260,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 261,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 262,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 263,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 264,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 265,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 266,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 267,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 268,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 269,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 270,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 272,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 273,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 273,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 274,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 276,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 281,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 282,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 282,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 282,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 282,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 282,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 282,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 282,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 282,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 282,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: Identifier,
        lexeme: "checkcompt",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: Identifier,
        lexeme: "msg",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: Identifier,
        lexeme: "code",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: Identifier,
        lexeme: "msg",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: Identifier,
        lexeme: "code",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 288,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: Identifier,
        lexeme: "checkcompt",
        computed_lexeme: None,
        line: 290,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 290,
    },
    Token {
        kind: String,
        lexeme: "\"divide by zero\"",
        computed_lexeme: None,
        line: 290,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 290,
    },
    Token {
        kind: String,
        lexeme: "\"return 2 // 0\"",
        computed_lexeme: None,
        line: 290,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 290,
    },
    Token {
        kind: Identifier,
        lexeme: "checkcompt",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: Identifier,
        lexeme: "msgf2i",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: String,
        lexeme: "\"return 2.3 >> 0\"",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: Identifier,
        lexeme: "checkcompt",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Identifier,
        lexeme: "msgf2i",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: String,
        lexeme: "\"return 2.0^%d & 1\"",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 292,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Identifier,
        lexeme: "checkcompt",
        computed_lexeme: None,
        line: 293,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 293,
    },
    Token {
        kind: String,
        lexeme: "\"field 'huge'\"",
        computed_lexeme: None,
        line: 293,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 293,
    },
    Token {
        kind: String,
        lexeme: "\"return math.huge << 1\"",
        computed_lexeme: None,
        line: 293,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 293,
    },
    Token {
        kind: Identifier,
        lexeme: "checkcompt",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Identifier,
        lexeme: "msgf2i",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: String,
        lexeme: "\"return 1 | 2.0^%d\"",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 294,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Identifier,
        lexeme: "checkcompt",
        computed_lexeme: None,
        line: 295,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 295,
    },
    Token {
        kind: Identifier,
        lexeme: "msgf2i",
        computed_lexeme: None,
        line: 295,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 295,
    },
    Token {
        kind: String,
        lexeme: "\"return 2.3 ~ 0.0\"",
        computed_lexeme: None,
        line: 295,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 295,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: BitOr,
        lexeme: "|",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Identifier,
        lexeme: "msgf2i",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Identifier,
        lexeme: "msgf2i",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: Identifier,
        lexeme: "msgf2i",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 302,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 302,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 304,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 304,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 304,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 304,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 304,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 306,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 306,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 307,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 307,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 308,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 308,
    },
    Token {
        kind: Identifier,
        lexeme: "msgf2i",
        computed_lexeme: None,
        line: 308,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 308,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 308,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 308,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 308,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 308,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 308,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 308,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 309,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 309,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 309,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 309,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 310,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 310,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 310,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 310,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 310,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 311,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 311,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 311,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 311,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 311,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 311,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 311,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Identifier,
        lexeme: "mf",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 313,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 313,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 314,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 314,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 314,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 314,
    },
    Token {
        kind: Identifier,
        lexeme: "mf",
        computed_lexeme: None,
        line: 314,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 314,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 314,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 314,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 314,
    },
    Token {
        kind: Identifier,
        lexeme: "mf",
        computed_lexeme: None,
        line: 314,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 314,
    },
    Token {
        kind: Identifier,
        lexeme: "mf",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "mf",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "mf",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 316,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "mf",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 319,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 320,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 321,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: String,
        lexeme: "\"no integer rep\"",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 322,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: String,
        lexeme: "\"no integer rep\"",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 323,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 324,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "f2i",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 327,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 332,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 332,
    },
    Token {
        kind: String,
        lexeme: "\"2\"",
        computed_lexeme: None,
        line: 332,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 332,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 332,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 332,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 332,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 332,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 333,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 333,
    },
    Token {
        kind: String,
        lexeme: "\"2 \"",
        computed_lexeme: None,
        line: 333,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 333,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 333,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 333,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 333,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 333,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 334,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 334,
    },
    Token {
        kind: String,
        lexeme: "\" -2 \"",
        computed_lexeme: None,
        line: 334,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 334,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 334,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 334,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 334,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 334,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 334,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 335,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 335,
    },
    Token {
        kind: String,
        lexeme: "\" -0xa \"",
        computed_lexeme: None,
        line: 335,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 335,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 335,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 335,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 335,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 335,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 335,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 339,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: Identifier,
        lexeme: "tostring",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 341,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: Identifier,
        lexeme: "tostring",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 342,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 345,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 345,
    },
    Token {
        kind: Identifier,
        lexeme: "incd",
        computed_lexeme: None,
        line: 345,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 345,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 345,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 345,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: String,
        lexeme: "\"%d\"",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 346,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: Identifier,
        lexeme: "gsub",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: String,
        lexeme: "\"%d$\"",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: Identifier,
        lexeme: "d",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 347,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 348,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 348,
    },
    Token {
        kind: Identifier,
        lexeme: "d",
        computed_lexeme: None,
        line: 348,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 348,
    },
    Token {
        kind: String,
        lexeme: "'9'",
        computed_lexeme: None,
        line: 348,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 348,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: Identifier,
        lexeme: "char",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: Identifier,
        lexeme: "byte",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: Identifier,
        lexeme: "d",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 349,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 349,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 350,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 350,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 351,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 351,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 352,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: Identifier,
        lexeme: "incd",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 355,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 355,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: Identifier,
        lexeme: "incd",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 356,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 356,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: String,
        lexeme: "\"1\"",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: String,
        lexeme: "\"0\"",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: Number,
        lexeme: "30",
        computed_lexeme: Some(
            "30",
        ),
        line: 359,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: Number,
        lexeme: "1e30",
        computed_lexeme: Some(
            "1e30",
        ),
        line: 359,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 359,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: String,
        lexeme: "\"-1\"",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: String,
        lexeme: "\"0\"",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Number,
        lexeme: "30",
        computed_lexeme: Some(
            "30",
        ),
        line: 360,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Number,
        lexeme: "1e30",
        computed_lexeme: Some(
            "1e30",
        ),
        line: 360,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 360,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: String,
        lexeme: "\"0x1\"",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: String,
        lexeme: "\"0\"",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: Number,
        lexeme: "30",
        computed_lexeme: Some(
            "30",
        ),
        line: 363,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 363,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 363,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: String,
        lexeme: "\"return \"",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 366,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: String,
        lexeme: "\"return \"",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 367,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 369,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 369,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 369,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 369,
    },
    Token {
        kind: Number,
        lexeme: "10000000000000000000000.0",
        computed_lexeme: Some(
            "10000000000000000000000.0",
        ),
        line: 369,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 369,
    },
    Token {
        kind: Number,
        lexeme: "10000000000000000000000",
        computed_lexeme: Some(
            "10000000000000000000000",
        ),
        line: 369,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 369,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 369,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 370,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 370,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 370,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 370,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 370,
    },
    Token {
        kind: Number,
        lexeme: "10000000000000000000000.0",
        computed_lexeme: Some(
            "10000000000000000000000.0",
        ),
        line: 370,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 370,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 370,
    },
    Token {
        kind: Number,
        lexeme: "10000000000000000000000",
        computed_lexeme: Some(
            "10000000000000000000000",
        ),
        line: 370,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 370,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 370,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 371,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 377,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 377,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 377,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 377,
    },
    Token {
        kind: Number,
        lexeme: "3.4",
        computed_lexeme: Some(
            "3.4",
        ),
        line: 377,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 377,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 377,
    },
    Token {
        kind: Number,
        lexeme: "3.4",
        computed_lexeme: Some(
            "3.4",
        ),
        line: 377,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 377,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 378,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 378,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 378,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 378,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 378,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 378,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 378,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 378,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 378,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 378,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 378,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 378,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 379,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 380,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 380,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 380,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 380,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 380,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 380,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 380,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 380,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 380,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 380,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 380,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 380,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 380,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 383,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 383,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 383,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 383,
    },
    Token {
        kind: String,
        lexeme: "\"0\"",
        computed_lexeme: None,
        line: 383,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 383,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 383,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 383,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 383,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 384,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 384,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 384,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 384,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 384,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 384,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 384,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 384,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 385,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 385,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 385,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 385,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 385,
    },
    Token {
        kind: String,
        lexeme: "\"  \"",
        computed_lexeme: None,
        line: 385,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 385,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 385,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 386,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 386,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 386,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 386,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 386,
    },
    Token {
        kind: String,
        lexeme: "\"-\"",
        computed_lexeme: None,
        line: 386,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 386,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 386,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 387,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 387,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 387,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 387,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 387,
    },
    Token {
        kind: String,
        lexeme: "\"  -0x \"",
        computed_lexeme: None,
        line: 387,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 387,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 387,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 388,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 388,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 388,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 388,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 388,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 388,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 388,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: String,
        lexeme: "'+0.01'",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 389,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: Number,
        lexeme: "100",
        computed_lexeme: Some(
            "100",
        ),
        line: 389,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: String,
        lexeme: "'+.01'",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: Number,
        lexeme: "0.01",
        computed_lexeme: Some(
            "0.01",
        ),
        line: 389,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 389,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 390,
    },
    Token {
        kind: String,
        lexeme: "'.01'",
        computed_lexeme: None,
        line: 390,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 390,
    },
    Token {
        kind: Number,
        lexeme: "0.01",
        computed_lexeme: Some(
            "0.01",
        ),
        line: 390,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 390,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 390,
    },
    Token {
        kind: String,
        lexeme: "'-1.'",
        computed_lexeme: None,
        line: 390,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 390,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 390,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 390,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 390,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 391,
    },
    Token {
        kind: String,
        lexeme: "'+1.'",
        computed_lexeme: None,
        line: 391,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 391,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 391,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 391,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 392,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 392,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 392,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 392,
    },
    Token {
        kind: String,
        lexeme: "'+ 0.01'",
        computed_lexeme: None,
        line: 392,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 392,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 392,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 392,
    },
    Token {
        kind: String,
        lexeme: "'+.e1'",
        computed_lexeme: None,
        line: 392,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 392,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 393,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 393,
    },
    Token {
        kind: String,
        lexeme: "'1e'",
        computed_lexeme: None,
        line: 393,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 393,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 393,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 393,
    },
    Token {
        kind: String,
        lexeme: "'1.0e+'",
        computed_lexeme: None,
        line: 393,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 393,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 394,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 394,
    },
    Token {
        kind: String,
        lexeme: "'.'",
        computed_lexeme: None,
        line: 394,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 394,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 395,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 395,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 395,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 395,
    },
    Token {
        kind: String,
        lexeme: "'-012'",
        computed_lexeme: None,
        line: 395,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 395,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 395,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 395,
    },
    Token {
        kind: Number,
        lexeme: "010",
        computed_lexeme: Some(
            "010",
        ),
        line: 395,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 395,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 395,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 395,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: String,
        lexeme: "'-1.2e2'",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: Number,
        lexeme: "120",
        computed_lexeme: Some(
            "120",
        ),
        line: 396,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 396,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: String,
        lexeme: "\"0xffffffffffff\"",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 398,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 398,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: Number,
        lexeme: "12",
        computed_lexeme: Some(
            "12",
        ),
        line: 398,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 398,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 398,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: String,
        lexeme: "\"0x\"",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: String,
        lexeme: "\"f\"",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 399,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 399,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 399,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: String,
        lexeme: "\"-0x\"",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: String,
        lexeme: "\"f\"",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 400,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 400,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 400,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 403,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 403,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 403,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 403,
    },
    Token {
        kind: String,
        lexeme: "'  001010  '",
        computed_lexeme: None,
        line: 403,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 403,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 403,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 403,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 403,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 403,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 403,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 404,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 404,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 404,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 404,
    },
    Token {
        kind: String,
        lexeme: "'  001010  '",
        computed_lexeme: None,
        line: 404,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 404,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 404,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 404,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 404,
    },
    Token {
        kind: Number,
        lexeme: "001010",
        computed_lexeme: Some(
            "001010",
        ),
        line: 404,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 404,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 405,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 405,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 405,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 405,
    },
    Token {
        kind: String,
        lexeme: "'  -1010  '",
        computed_lexeme: None,
        line: 405,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 405,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 405,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 405,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 405,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 405,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 405,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 405,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 406,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 406,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 406,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 406,
    },
    Token {
        kind: String,
        lexeme: "'10'",
        computed_lexeme: None,
        line: 406,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 406,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 406,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 406,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 406,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 406,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 406,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 407,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 407,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 407,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 407,
    },
    Token {
        kind: String,
        lexeme: "'  -10  '",
        computed_lexeme: None,
        line: 407,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 407,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 407,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 407,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 407,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 407,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 407,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 407,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 408,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 408,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 408,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 408,
    },
    Token {
        kind: String,
        lexeme: "'  +1Z  '",
        computed_lexeme: None,
        line: 408,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 408,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 408,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 408,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 408,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 408,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 408,
    },
    Token {
        kind: Number,
        lexeme: "35",
        computed_lexeme: Some(
            "35",
        ),
        line: 408,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 408,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: String,
        lexeme: "'  -1z  '",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 409,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 409,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: Number,
        lexeme: "35",
        computed_lexeme: Some(
            "35",
        ),
        line: 409,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 409,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: String,
        lexeme: "'-fFfa'",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 410,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 410,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 410,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 410,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 410,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 410,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 410,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 410,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 410,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: String,
        lexeme: "'1'",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 411,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 411,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 411,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 411,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 411,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 411,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: String,
        lexeme: "'ffffFFFF'",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 412,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 412,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 412,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 412,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 412,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: String,
        lexeme: "'0ffffFFFF'",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 413,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 413,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 413,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 413,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 413,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: String,
        lexeme: "'-0ffffffFFFF'",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 414,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 414,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 414,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: Number,
        lexeme: "40",
        computed_lexeme: Some(
            "40",
        ),
        line: 414,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 414,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 415,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 415,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 415,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 415,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 415,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 415,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 415,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 416,
    },
    Token {
        kind: Identifier,
        lexeme: "i2",
        computed_lexeme: None,
        line: 416,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 416,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 416,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 416,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 416,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Identifier,
        lexeme: "i10",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Identifier,
        lexeme: "i2",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Identifier,
        lexeme: "i2",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Identifier,
        lexeme: "i2",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Identifier,
        lexeme: "i2",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Identifier,
        lexeme: "i2",
        computed_lexeme: None,
        line: 417,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: String,
        lexeme: "'\\t10000000000\\t'",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: Identifier,
        lexeme: "i10",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 418,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 419,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 421,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 421,
    },
    Token {
        kind: Identifier,
        lexeme: "_soft",
        computed_lexeme: None,
        line: 421,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 421,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: String,
        lexeme: "\"0x\"",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: String,
        lexeme: "\"f\"",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Number,
        lexeme: "13",
        computed_lexeme: Some(
            "13",
        ),
        line: 423,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: String,
        lexeme: "\".0\"",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 423,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 423,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Number,
        lexeme: "13",
        computed_lexeme: Some(
            "13",
        ),
        line: 423,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 423,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 423,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: String,
        lexeme: "\"0x\"",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: String,
        lexeme: "\"f\"",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Number,
        lexeme: "150",
        computed_lexeme: Some(
            "150",
        ),
        line: 424,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: String,
        lexeme: "\".0\"",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 424,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 424,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Number,
        lexeme: "150",
        computed_lexeme: Some(
            "150",
        ),
        line: 424,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 424,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 424,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: String,
        lexeme: "\"0x\"",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: String,
        lexeme: "\"f\"",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Number,
        lexeme: "300",
        computed_lexeme: Some(
            "300",
        ),
        line: 425,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: String,
        lexeme: "\".0\"",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 425,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 425,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Number,
        lexeme: "300",
        computed_lexeme: Some(
            "300",
        ),
        line: 425,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 425,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 425,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: String,
        lexeme: "\"0x\"",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: String,
        lexeme: "\"f\"",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Number,
        lexeme: "500",
        computed_lexeme: Some(
            "500",
        ),
        line: 426,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: String,
        lexeme: "\".0\"",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 426,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 426,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Number,
        lexeme: "500",
        computed_lexeme: Some(
            "500",
        ),
        line: 426,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 426,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 426,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: String,
        lexeme: "'0x3.'",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: String,
        lexeme: "'0'",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: Number,
        lexeme: "1000",
        computed_lexeme: Some(
            "1000",
        ),
        line: 427,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 427,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 427,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: String,
        lexeme: "'0x'",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: String,
        lexeme: "'0'",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: Number,
        lexeme: "1000",
        computed_lexeme: Some(
            "1000",
        ),
        line: 428,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 428,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 428,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: String,
        lexeme: "'0x0.'",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: String,
        lexeme: "'0'",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Number,
        lexeme: "13",
        computed_lexeme: Some(
            "13",
        ),
        line: 429,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: String,
        lexeme: "\"1\"",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 429,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 429,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Number,
        lexeme: "14",
        computed_lexeme: Some(
            "14",
        ),
        line: 429,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 429,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: String,
        lexeme: "'0x0.'",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: String,
        lexeme: "'0'",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Number,
        lexeme: "150",
        computed_lexeme: Some(
            "150",
        ),
        line: 430,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: String,
        lexeme: "\"1\"",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 430,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 430,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Number,
        lexeme: "151",
        computed_lexeme: Some(
            "151",
        ),
        line: 430,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 430,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: String,
        lexeme: "'0x0.'",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: String,
        lexeme: "'0'",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Number,
        lexeme: "300",
        computed_lexeme: Some(
            "300",
        ),
        line: 431,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: String,
        lexeme: "\"1\"",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 431,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 431,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Number,
        lexeme: "301",
        computed_lexeme: Some(
            "301",
        ),
        line: 431,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 431,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: String,
        lexeme: "'0x0.'",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: String,
        lexeme: "'0'",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Number,
        lexeme: "500",
        computed_lexeme: Some(
            "500",
        ),
        line: 432,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: String,
        lexeme: "\"1\"",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 432,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 432,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Number,
        lexeme: "501",
        computed_lexeme: Some(
            "501",
        ),
        line: 432,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 432,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: String,
        lexeme: "'0xe03'",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: String,
        lexeme: "'0'",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: Number,
        lexeme: "1000",
        computed_lexeme: Some(
            "1000",
        ),
        line: 434,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: String,
        lexeme: "'p-4000'",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: Number,
        lexeme: "3587.0",
        computed_lexeme: Some(
            "3587.0",
        ),
        line: 434,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 434,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: String,
        lexeme: "'0x.'",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: String,
        lexeme: "'0'",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: Number,
        lexeme: "1000",
        computed_lexeme: Some(
            "1000",
        ),
        line: 435,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: String,
        lexeme: "'74p4004'",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: Number,
        lexeme: "0x7.4",
        computed_lexeme: Some(
            "7.25",
        ),
        line: 435,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 435,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 436,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 440,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 440,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 440,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 440,
    },
    Token {
        kind: TripleDot,
        lexeme: "...",
        computed_lexeme: None,
        line: 440,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 440,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 441,
    },
    Token {
        kind: Identifier,
        lexeme: "select",
        computed_lexeme: None,
        line: 441,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 441,
    },
    Token {
        kind: String,
        lexeme: "'#'",
        computed_lexeme: None,
        line: 441,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 441,
    },
    Token {
        kind: TripleDot,
        lexeme: "...",
        computed_lexeme: None,
        line: 441,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 441,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 441,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 441,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 441,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 442,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 442,
    },
    Token {
        kind: TripleDot,
        lexeme: "...",
        computed_lexeme: None,
        line: 442,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 442,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 443,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 444,
    },
    Token {
        kind: String,
        lexeme: "\"***\"",
        computed_lexeme: None,
        line: 444,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 445,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 446,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: String,
        lexeme: "'fFfa'",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 448,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 448,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: String,
        lexeme: "'099'",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: Number,
        lexeme: "8",
        computed_lexeme: Some(
            "8",
        ),
        line: 449,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 449,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: String,
        lexeme: "'1\\0'",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 450,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 450,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: String,
        lexeme: "''",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: Number,
        lexeme: "8",
        computed_lexeme: Some(
            "8",
        ),
        line: 451,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 451,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: String,
        lexeme: "'  '",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 452,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 452,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: String,
        lexeme: "'  '",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 453,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 453,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: String,
        lexeme: "'0xf'",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 454,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 454,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: String,
        lexeme: "'inf'",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 456,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: String,
        lexeme: "' INF '",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 457,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: String,
        lexeme: "'Nan'",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 458,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: String,
        lexeme: "'nan'",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 459,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: String,
        lexeme: "'  '",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 461,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: String,
        lexeme: "''",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 462,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: String,
        lexeme: "'1  a'",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 463,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: String,
        lexeme: "'1  a'",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 464,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 464,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: String,
        lexeme: "'1\\0'",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 465,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: String,
        lexeme: "'1 \\0'",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 466,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: String,
        lexeme: "'1\\0 '",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 467,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: String,
        lexeme: "'e1'",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 468,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: String,
        lexeme: "'e  1'",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 469,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: String,
        lexeme: "' 3.4.5 '",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 470,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 475,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 475,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 475,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 475,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 475,
    },
    Token {
        kind: String,
        lexeme: "'0x'",
        computed_lexeme: None,
        line: 475,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 475,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 475,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 476,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 476,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 476,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 476,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 476,
    },
    Token {
        kind: String,
        lexeme: "'x'",
        computed_lexeme: None,
        line: 476,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 476,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 476,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 477,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 477,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 477,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 477,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 477,
    },
    Token {
        kind: String,
        lexeme: "'x3'",
        computed_lexeme: None,
        line: 477,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 477,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 477,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 478,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 478,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 478,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 478,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 478,
    },
    Token {
        kind: String,
        lexeme: "'0x3.3.3'",
        computed_lexeme: None,
        line: 478,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 478,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 478,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 479,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 479,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 479,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 479,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 479,
    },
    Token {
        kind: String,
        lexeme: "'00x2'",
        computed_lexeme: None,
        line: 479,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 479,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 479,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 480,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 480,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 480,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 480,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 480,
    },
    Token {
        kind: String,
        lexeme: "'0x 2'",
        computed_lexeme: None,
        line: 480,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 480,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 480,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 481,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 481,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 481,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 481,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 481,
    },
    Token {
        kind: String,
        lexeme: "'0 x2'",
        computed_lexeme: None,
        line: 481,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 481,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 481,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 482,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 482,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 482,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 482,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 482,
    },
    Token {
        kind: String,
        lexeme: "'23x'",
        computed_lexeme: None,
        line: 482,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 482,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 482,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 483,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 483,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 483,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 483,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 483,
    },
    Token {
        kind: String,
        lexeme: "'- 0xaa'",
        computed_lexeme: None,
        line: 483,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 483,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 483,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 484,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 484,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 484,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 484,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 484,
    },
    Token {
        kind: String,
        lexeme: "'-0xaaP '",
        computed_lexeme: None,
        line: 484,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 484,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 484,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 485,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 485,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 485,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 485,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 485,
    },
    Token {
        kind: String,
        lexeme: "'0x0.51p'",
        computed_lexeme: None,
        line: 485,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 485,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 485,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 486,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 486,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 486,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 486,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 486,
    },
    Token {
        kind: String,
        lexeme: "'0x5p+-2'",
        computed_lexeme: None,
        line: 486,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 486,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 486,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 491,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 491,
    },
    Token {
        kind: Number,
        lexeme: "0x10",
        computed_lexeme: Some(
            "0x10",
        ),
        line: 491,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 491,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 491,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 491,
    },
    Token {
        kind: Number,
        lexeme: "0xfff",
        computed_lexeme: Some(
            "0xfff",
        ),
        line: 491,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 491,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 491,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 491,
    },
    Token {
        kind: Number,
        lexeme: "12",
        computed_lexeme: Some(
            "12",
        ),
        line: 491,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 491,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 491,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 491,
    },
    Token {
        kind: Number,
        lexeme: "0XFB",
        computed_lexeme: Some(
            "0XFB",
        ),
        line: 491,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 491,
    },
    Token {
        kind: Number,
        lexeme: "251",
        computed_lexeme: Some(
            "251",
        ),
        line: 491,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 491,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 492,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 492,
    },
    Token {
        kind: Number,
        lexeme: "0x0p12",
        computed_lexeme: Some(
            "0",
        ),
        line: 492,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 492,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 492,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 492,
    },
    Token {
        kind: Number,
        lexeme: "0x.0p-3",
        computed_lexeme: Some(
            "0",
        ),
        line: 492,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 492,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 492,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 492,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 493,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 493,
    },
    Token {
        kind: Number,
        lexeme: "0xFFFFFFFF",
        computed_lexeme: Some(
            "0xFFFFFFFF",
        ),
        line: 493,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 493,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 493,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 493,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 493,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 493,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 493,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 493,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 493,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 493,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 494,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 494,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 494,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 494,
    },
    Token {
        kind: String,
        lexeme: "'+0x2'",
        computed_lexeme: None,
        line: 494,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 494,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 494,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 494,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 494,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 495,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 495,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 495,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 495,
    },
    Token {
        kind: String,
        lexeme: "'-0xaA'",
        computed_lexeme: None,
        line: 495,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 495,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 495,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 495,
    },
    Token {
        kind: Number,
        lexeme: "170",
        computed_lexeme: Some(
            "170",
        ),
        line: 495,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 495,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: String,
        lexeme: "'-0xffFFFfff'",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 496,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 496,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 496,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 496,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 499,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 499,
    },
    Token {
        kind: Number,
        lexeme: "0E+1",
        computed_lexeme: Some(
            "0e+1",
        ),
        line: 499,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 499,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 499,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 499,
    },
    Token {
        kind: Number,
        lexeme: "0xE",
        computed_lexeme: Some(
            "0xE",
        ),
        line: 499,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 499,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 499,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 499,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 499,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 499,
    },
    Token {
        kind: Number,
        lexeme: "0xe",
        computed_lexeme: Some(
            "0xe",
        ),
        line: 499,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 499,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 499,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 499,
    },
    Token {
        kind: Number,
        lexeme: "13",
        computed_lexeme: Some(
            "13",
        ),
        line: 499,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 499,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 504,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 504,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 504,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 504,
    },
    Token {
        kind: String,
        lexeme: "'  0x2.5  '",
        computed_lexeme: None,
        line: 504,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 504,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 504,
    },
    Token {
        kind: Number,
        lexeme: "0x25",
        computed_lexeme: Some(
            "0x25",
        ),
        line: 504,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 504,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 504,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 504,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 505,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 505,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 505,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 505,
    },
    Token {
        kind: String,
        lexeme: "'  -0x2.5  '",
        computed_lexeme: None,
        line: 505,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 505,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 505,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 505,
    },
    Token {
        kind: Number,
        lexeme: "0x25",
        computed_lexeme: Some(
            "0x25",
        ),
        line: 505,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 505,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 505,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 505,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 506,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 506,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 506,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 506,
    },
    Token {
        kind: String,
        lexeme: "'  +0x0.51p+8  '",
        computed_lexeme: None,
        line: 506,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 506,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 506,
    },
    Token {
        kind: Number,
        lexeme: "0x51",
        computed_lexeme: Some(
            "0x51",
        ),
        line: 506,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 506,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 507,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 507,
    },
    Token {
        kind: Number,
        lexeme: "0x.FfffFFFF",
        computed_lexeme: Some(
            "0.9999999997671694",
        ),
        line: 507,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 507,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 507,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 507,
    },
    Token {
        kind: String,
        lexeme: "'0x.00000001'",
        computed_lexeme: None,
        line: 507,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 507,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 508,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 508,
    },
    Token {
        kind: String,
        lexeme: "'0xA.a'",
        computed_lexeme: None,
        line: 508,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 508,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 508,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 508,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 508,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 508,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 508,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 508,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 508,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 508,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 509,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 509,
    },
    Token {
        kind: Number,
        lexeme: "0xa.aP4",
        computed_lexeme: Some(
            "170",
        ),
        line: 509,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 509,
    },
    Token {
        kind: Number,
        lexeme: "0XAA",
        computed_lexeme: Some(
            "0XAA",
        ),
        line: 509,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 509,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 510,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 510,
    },
    Token {
        kind: Number,
        lexeme: "0x4P-2",
        computed_lexeme: Some(
            "1",
        ),
        line: 510,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 510,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 510,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 510,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 511,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 511,
    },
    Token {
        kind: Number,
        lexeme: "0x1.1",
        computed_lexeme: Some(
            "1.0625",
        ),
        line: 511,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 511,
    },
    Token {
        kind: String,
        lexeme: "'0x1.'",
        computed_lexeme: None,
        line: 511,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 511,
    },
    Token {
        kind: String,
        lexeme: "'+0x.1'",
        computed_lexeme: None,
        line: 511,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 511,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 512,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 512,
    },
    Token {
        kind: Number,
        lexeme: "0Xabcdef.0",
        computed_lexeme: Some(
            "703711",
        ),
        line: 512,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 512,
    },
    Token {
        kind: Number,
        lexeme: "0x.ABCDEFp+24",
        computed_lexeme: Some(
            "11259376",
        ),
        line: 512,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 512,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 515,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 515,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 515,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 515,
    },
    Token {
        kind: Number,
        lexeme: "1.",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 515,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 515,
    },
    Token {
        kind: Number,
        lexeme: ".1",
        computed_lexeme: Some(
            "0.1",
        ),
        line: 515,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 515,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 516,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 516,
    },
    Token {
        kind: Number,
        lexeme: "100.0",
        computed_lexeme: Some(
            "100.0",
        ),
        line: 516,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 516,
    },
    Token {
        kind: Number,
        lexeme: "1E2",
        computed_lexeme: Some(
            "1e2",
        ),
        line: 516,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 516,
    },
    Token {
        kind: Number,
        lexeme: ".01",
        computed_lexeme: Some(
            "0.01",
        ),
        line: 516,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 516,
    },
    Token {
        kind: Number,
        lexeme: "1e-2",
        computed_lexeme: Some(
            "1e-2",
        ),
        line: 516,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 516,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 517,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 517,
    },
    Token {
        kind: Number,
        lexeme: "1111111111",
        computed_lexeme: Some(
            "1111111111",
        ),
        line: 517,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 517,
    },
    Token {
        kind: Number,
        lexeme: "1111111110",
        computed_lexeme: Some(
            "1111111110",
        ),
        line: 517,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 517,
    },
    Token {
        kind: Number,
        lexeme: "1000.00e-03",
        computed_lexeme: Some(
            "1000.00e-03",
        ),
        line: 517,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 517,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 518,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 518,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 518,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 518,
    },
    Token {
        kind: String,
        lexeme: "'1.'",
        computed_lexeme: None,
        line: 518,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 518,
    },
    Token {
        kind: String,
        lexeme: "'.1'",
        computed_lexeme: None,
        line: 518,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 518,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 519,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 519,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 519,
    },
    Token {
        kind: String,
        lexeme: "'1111111111'",
        computed_lexeme: None,
        line: 519,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 519,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 519,
    },
    Token {
        kind: String,
        lexeme: "'1111111110'",
        computed_lexeme: None,
        line: 519,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 519,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 520,
    },
    Token {
        kind: String,
        lexeme: "\"  +0.001e+3 \\n\\t\"",
        computed_lexeme: None,
        line: 520,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 520,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 522,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 522,
    },
    Token {
        kind: Number,
        lexeme: "0.1e-30",
        computed_lexeme: Some(
            "0.1e-30",
        ),
        line: 522,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 522,
    },
    Token {
        kind: Number,
        lexeme: "0.9E-31",
        computed_lexeme: Some(
            "0.9e-31",
        ),
        line: 522,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 522,
    },
    Token {
        kind: Number,
        lexeme: "0.9E30",
        computed_lexeme: Some(
            "0.9e30",
        ),
        line: 522,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 522,
    },
    Token {
        kind: Number,
        lexeme: "0.1e31",
        computed_lexeme: Some(
            "0.1e31",
        ),
        line: 522,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 522,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 524,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 524,
    },
    Token {
        kind: Number,
        lexeme: "0.123456",
        computed_lexeme: Some(
            "0.123456",
        ),
        line: 524,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 524,
    },
    Token {
        kind: Number,
        lexeme: "0.123455",
        computed_lexeme: Some(
            "0.123455",
        ),
        line: 524,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 524,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 526,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 526,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 526,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 526,
    },
    Token {
        kind: String,
        lexeme: "'+1.23E18'",
        computed_lexeme: None,
        line: 526,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 526,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 526,
    },
    Token {
        kind: Number,
        lexeme: "1.23",
        computed_lexeme: Some(
            "1.23",
        ),
        line: 526,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 526,
    },
    Token {
        kind: Number,
        lexeme: "10.0",
        computed_lexeme: Some(
            "10.0",
        ),
        line: 526,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 526,
    },
    Token {
        kind: Number,
        lexeme: "18",
        computed_lexeme: Some(
            "18",
        ),
        line: 526,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 526,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 529,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 529,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 529,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 529,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 529,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 529,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 529,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 530,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 531,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 531,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 531,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 531,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 531,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 531,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 531,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 532,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 533,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 533,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 533,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 533,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 533,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 533,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 533,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 534,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 535,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 535,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 535,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 535,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 535,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 535,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 535,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 536,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: Number,
        lexeme: "1.3",
        computed_lexeme: Some(
            "1.3",
        ),
        line: 537,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: Number,
        lexeme: "1.4",
        computed_lexeme: Some(
            "1.4",
        ),
        line: 537,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: Number,
        lexeme: "1.3",
        computed_lexeme: Some(
            "1.3",
        ),
        line: 537,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: Number,
        lexeme: "1.4",
        computed_lexeme: Some(
            "1.4",
        ),
        line: 537,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: Number,
        lexeme: "1.3",
        computed_lexeme: Some(
            "1.3",
        ),
        line: 537,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: Number,
        lexeme: "1.3",
        computed_lexeme: Some(
            "1.3",
        ),
        line: 537,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: Number,
        lexeme: "1.3",
        computed_lexeme: Some(
            "1.3",
        ),
        line: 537,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: Number,
        lexeme: "1.3",
        computed_lexeme: Some(
            "1.3",
        ),
        line: 537,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 537,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 540,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 540,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 540,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 540,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 540,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 540,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 540,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 540,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 540,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 540,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 540,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 540,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 541,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 541,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 541,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 541,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 541,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 541,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 541,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 541,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 541,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 541,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 541,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 541,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 541,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 542,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 542,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 542,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 542,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 542,
    },
    Token {
        kind: Number,
        lexeme: "4.0",
        computed_lexeme: Some(
            "4.0",
        ),
        line: 542,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 542,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 542,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 542,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 542,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 542,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 542,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 543,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 543,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 543,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 543,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 543,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 543,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 543,
    },
    Token {
        kind: Number,
        lexeme: "3.0",
        computed_lexeme: Some(
            "3.0",
        ),
        line: 543,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 543,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 543,
    },
    Token {
        kind: Number,
        lexeme: "2.0",
        computed_lexeme: Some(
            "2.0",
        ),
        line: 543,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 543,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 543,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 544,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 544,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 544,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 544,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 544,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 544,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 544,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 544,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 544,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 544,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 544,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 544,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 544,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 545,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 545,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 545,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 545,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 545,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 545,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 545,
    },
    Token {
        kind: Number,
        lexeme: "5.0",
        computed_lexeme: Some(
            "5.0",
        ),
        line: 545,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 545,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 545,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 545,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 545,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 545,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 546,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 546,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 546,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 546,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 546,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 546,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 546,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 546,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 546,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 546,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 546,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 547,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 547,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 547,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 547,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 547,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 547,
    },
    Token {
        kind: Number,
        lexeme: "5.0",
        computed_lexeme: Some(
            "5.0",
        ),
        line: 547,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 547,
    },
    Token {
        kind: Number,
        lexeme: "4.0",
        computed_lexeme: Some(
            "4.0",
        ),
        line: 547,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 547,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 547,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 548,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 548,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 548,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 548,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 549,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: Number,
        lexeme: "5.0",
        computed_lexeme: Some(
            "5.0",
        ),
        line: 549,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: Number,
        lexeme: "4.0",
        computed_lexeme: Some(
            "4.0",
        ),
        line: 549,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 549,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 550,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 550,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 550,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 550,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 550,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 550,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 550,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 550,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 550,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 550,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 550,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 550,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 551,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 551,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 551,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 551,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 551,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 551,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 551,
    },
    Token {
        kind: Number,
        lexeme: "5.0",
        computed_lexeme: Some(
            "5.0",
        ),
        line: 551,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 551,
    },
    Token {
        kind: Number,
        lexeme: "1.0",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 551,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 551,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 551,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 552,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 552,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 552,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 552,
    },
    Token {
        kind: Number,
        lexeme: "4.25",
        computed_lexeme: Some(
            "4.25",
        ),
        line: 552,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 552,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 552,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 552,
    },
    Token {
        kind: Number,
        lexeme: "0.25",
        computed_lexeme: Some(
            "0.25",
        ),
        line: 552,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 552,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 552,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 553,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 553,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 553,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 553,
    },
    Token {
        kind: Number,
        lexeme: "10.0",
        computed_lexeme: Some(
            "10.0",
        ),
        line: 553,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 553,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 553,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 553,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 553,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 553,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 553,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 554,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 554,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 554,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 554,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 554,
    },
    Token {
        kind: Number,
        lexeme: "10.0",
        computed_lexeme: Some(
            "10.0",
        ),
        line: 554,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 554,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 554,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 554,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 554,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 554,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 554,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 555,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 555,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 555,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 555,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 555,
    },
    Token {
        kind: Number,
        lexeme: "10.0",
        computed_lexeme: Some(
            "10.0",
        ),
        line: 555,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 555,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 555,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 555,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 555,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 555,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 555,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 555,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 556,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 556,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 556,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Number,
        lexeme: "0.001",
        computed_lexeme: Some(
            "0.001",
        ),
        line: 557,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Number,
        lexeme: "3.141",
        computed_lexeme: Some(
            "3.141",
        ),
        line: 557,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 557,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 559,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 560,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 560,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 560,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 560,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 560,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 560,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 560,
    },
    Token {
        kind: Number,
        lexeme: "20000",
        computed_lexeme: Some(
            "20000",
        ),
        line: 560,
    },
    Token {
        kind: While,
        lexeme: "while",
        computed_lexeme: None,
        line: 561,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 561,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 561,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 561,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 561,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 562,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 562,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 562,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 562,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 562,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 562,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 562,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 562,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 562,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 562,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 563,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 563,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 563,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 563,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 563,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 563,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 563,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 563,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 564,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 564,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 564,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 564,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 564,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 565,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 566,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 566,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 566,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 567,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 568,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 570,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 570,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 570,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 571,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 571,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 571,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 571,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 571,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 571,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 571,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 571,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 571,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 571,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 571,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 571,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 572,
    },
    Token {
        kind: Identifier,
        lexeme: "delta",
        computed_lexeme: None,
        line: 572,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 572,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 572,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 572,
    },
    Token {
        kind: Number,
        lexeme: "1000",
        computed_lexeme: Some(
            "1000",
        ),
        line: 572,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Number,
        lexeme: "2.1",
        computed_lexeme: Some(
            "2.1",
        ),
        line: 573,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 573,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Number,
        lexeme: "0.1",
        computed_lexeme: Some(
            "0.1",
        ),
        line: 573,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Identifier,
        lexeme: "delta",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 573,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Number,
        lexeme: "2.1",
        computed_lexeme: Some(
            "2.1",
        ),
        line: 574,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 574,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 574,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Number,
        lexeme: "0.1",
        computed_lexeme: Some(
            "0.1",
        ),
        line: 574,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Identifier,
        lexeme: "delta",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 574,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Number,
        lexeme: "2.1",
        computed_lexeme: Some(
            "2.1",
        ),
        line: 575,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 575,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Number,
        lexeme: "0.1",
        computed_lexeme: Some(
            "0.1",
        ),
        line: 575,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 575,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Identifier,
        lexeme: "delta",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 575,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Number,
        lexeme: "2.1",
        computed_lexeme: Some(
            "2.1",
        ),
        line: 576,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 576,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Number,
        lexeme: "0.1",
        computed_lexeme: Some(
            "0.1",
        ),
        line: 576,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: Identifier,
        lexeme: "delta",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 576,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 577,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 581,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 581,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 581,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 581,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 581,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 581,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 581,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 581,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 582,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 582,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 582,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 582,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 582,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 582,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 582,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 582,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 583,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 583,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 583,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 583,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 583,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 584,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 584,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 585,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 586,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 587,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 589,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 589,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 589,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 589,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 589,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 589,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 589,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 590,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 590,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 590,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 590,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 590,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 590,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 590,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 590,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 591,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 591,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 591,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 591,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 591,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 592,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 592,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 592,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 593,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 594,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 595,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 597,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 598,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 598,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 598,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 598,
    },
    Token {
        kind: While,
        lexeme: "while",
        computed_lexeme: None,
        line: 599,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 599,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 599,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 599,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 599,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 599,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 599,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 599,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 599,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 600,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 600,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 600,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 600,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 600,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 601,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 601,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 601,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 601,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 601,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 602,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 604,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 604,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 604,
    },
    Token {
        kind: While,
        lexeme: "while",
        computed_lexeme: None,
        line: 605,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 605,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 605,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 605,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 605,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 605,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 605,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 605,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 605,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 606,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 606,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 606,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 606,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 606,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 606,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 606,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 606,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 606,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 606,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 606,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 606,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 606,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 606,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 607,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 607,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 607,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 607,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 607,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 608,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 609,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 611,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 611,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 611,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 611,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 611,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 611,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 611,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 611,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 611,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 611,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 611,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 612,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 612,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 612,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 612,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 612,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 612,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 612,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 612,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 612,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 612,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 612,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 613,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 613,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 613,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 614,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 614,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 614,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 615,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 615,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 615,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 615,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 615,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 615,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 615,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 615,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 615,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 615,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 617,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 617,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 617,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 617,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 617,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 617,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 617,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 617,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 617,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 618,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 618,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 618,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 618,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 618,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 618,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 618,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 618,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 618,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 619,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 619,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 619,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 619,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 619,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 619,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 619,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 619,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 619,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 619,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 623,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 623,
    },
    Token {
        kind: Identifier,
        lexeme: "_port",
        computed_lexeme: None,
        line: 623,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 623,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: Identifier,
        lexeme: "anan",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: Identifier,
        lexeme: "isNaN",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 624,
    },
    Token {
        kind: Identifier,
        lexeme: "anan",
        computed_lexeme: None,
        line: 625,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 625,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 625,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 625,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 625,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 625,
    },
    Token {
        kind: Identifier,
        lexeme: "anan",
        computed_lexeme: None,
        line: 626,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 626,
    },
    Token {
        kind: Number,
        lexeme: "1.3",
        computed_lexeme: Some(
            "1.3",
        ),
        line: 626,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 626,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 626,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 626,
    },
    Token {
        kind: Identifier,
        lexeme: "anan",
        computed_lexeme: None,
        line: 627,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 627,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 627,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 627,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 627,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 627,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 627,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 627,
    },
    Token {
        kind: Identifier,
        lexeme: "anan",
        computed_lexeme: None,
        line: 628,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 628,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 628,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 628,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 628,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 628,
    },
    Token {
        kind: Number,
        lexeme: "1e30",
        computed_lexeme: Some(
            "1e30",
        ),
        line: 628,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 628,
    },
    Token {
        kind: Identifier,
        lexeme: "anan",
        computed_lexeme: None,
        line: 629,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 629,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 629,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 629,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 629,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 629,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 629,
    },
    Token {
        kind: Number,
        lexeme: "1e30",
        computed_lexeme: Some(
            "1e30",
        ),
        line: 629,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 629,
    },
    Token {
        kind: Identifier,
        lexeme: "anan",
        computed_lexeme: None,
        line: 630,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 630,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 630,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 630,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 630,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 630,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 630,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 630,
    },
    Token {
        kind: Number,
        lexeme: "1e30",
        computed_lexeme: Some(
            "1e30",
        ),
        line: 630,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 630,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 631,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 631,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 631,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 631,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 631,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 631,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 631,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 631,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 631,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 631,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 632,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 632,
    },
    Token {
        kind: Number,
        lexeme: "1e30",
        computed_lexeme: Some(
            "1e30",
        ),
        line: 632,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 632,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 632,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 632,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 632,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 632,
    },
    Token {
        kind: Number,
        lexeme: "1e30",
        computed_lexeme: Some(
            "1e30",
        ),
        line: 632,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 632,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: Number,
        lexeme: "1e30",
        computed_lexeme: Some(
            "1e30",
        ),
        line: 633,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 633,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 634,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 634,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 635,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 635,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 635,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 636,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 640,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 640,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 640,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 640,
    },
    Token {
        kind: Identifier,
        lexeme: "ult",
        computed_lexeme: None,
        line: 640,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 640,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 640,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 640,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 640,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 640,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 640,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 641,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 641,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 641,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 641,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 641,
    },
    Token {
        kind: Identifier,
        lexeme: "ult",
        computed_lexeme: None,
        line: 641,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 641,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 641,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 641,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 641,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 641,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 641,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: Identifier,
        lexeme: "ult",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 642,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 642,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 642,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 643,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 643,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 643,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 643,
    },
    Token {
        kind: Identifier,
        lexeme: "ult",
        computed_lexeme: None,
        line: 643,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 643,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 643,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 643,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 643,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 643,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 643,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 643,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: Identifier,
        lexeme: "ult",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 644,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 644,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 644,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: Identifier,
        lexeme: "ult",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 645,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: Identifier,
        lexeme: "ult",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 646,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Identifier,
        lexeme: "sin",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Number,
        lexeme: "9.8",
        computed_lexeme: Some(
            "9.8",
        ),
        line: 649,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 649,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Identifier,
        lexeme: "cos",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Number,
        lexeme: "9.8",
        computed_lexeme: Some(
            "9.8",
        ),
        line: 649,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 649,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 649,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 649,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Identifier,
        lexeme: "tan",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 650,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 650,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 650,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "sin",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 651,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 651,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "cos",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 651,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 651,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 651,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "atan",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 652,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 652,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "acos",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 652,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 652,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 652,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Identifier,
        lexeme: "asin",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 653,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 653,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 653,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "deg",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 654,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Number,
        lexeme: "90",
        computed_lexeme: Some(
            "90",
        ),
        line: 654,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "rad",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Number,
        lexeme: "90",
        computed_lexeme: Some(
            "90",
        ),
        line: 654,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 654,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 654,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 655,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 655,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 655,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 655,
    },
    Token {
        kind: Identifier,
        lexeme: "abs",
        computed_lexeme: None,
        line: 655,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 655,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 655,
    },
    Token {
        kind: Number,
        lexeme: "10.43",
        computed_lexeme: Some(
            "10.43",
        ),
        line: 655,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 655,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 655,
    },
    Token {
        kind: Number,
        lexeme: "10.43",
        computed_lexeme: Some(
            "10.43",
        ),
        line: 655,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 655,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: Identifier,
        lexeme: "abs",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 656,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: Identifier,
        lexeme: "abs",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 657,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: Identifier,
        lexeme: "abs",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 658,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Identifier,
        lexeme: "atan",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 659,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 659,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 659,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 659,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 660,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 660,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 660,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 660,
    },
    Token {
        kind: Identifier,
        lexeme: "fmod",
        computed_lexeme: None,
        line: 660,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 660,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 660,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 660,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 660,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 660,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 660,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 660,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 660,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: Identifier,
        lexeme: "sqrt",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 661,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 661,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 661,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 661,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 662,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 662,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 662,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 662,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 662,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 663,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 663,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 663,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 663,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 664,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 664,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 664,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 664,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: Identifier,
        lexeme: "exp",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 665,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 665,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 665,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Identifier,
        lexeme: "sin",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 666,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Identifier,
        lexeme: "sin",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 666,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 666,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 666,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 669,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 669,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 669,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 669,
    },
    Token {
        kind: String,
        lexeme: "' 1.3e-2 '",
        computed_lexeme: None,
        line: 669,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 669,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 669,
    },
    Token {
        kind: Number,
        lexeme: "1.3e-2",
        computed_lexeme: Some(
            "1.3e-2",
        ),
        line: 669,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 669,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 670,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 670,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 670,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 670,
    },
    Token {
        kind: String,
        lexeme: "' -1.00000000000001 '",
        computed_lexeme: None,
        line: 670,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 670,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 670,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 670,
    },
    Token {
        kind: Number,
        lexeme: "1.00000000000001",
        computed_lexeme: Some(
            "1.00000000000001",
        ),
        line: 670,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 670,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 674,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 674,
    },
    Token {
        kind: Number,
        lexeme: "8388609",
        computed_lexeme: Some(
            "8388609",
        ),
        line: 674,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 674,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 674,
    },
    Token {
        kind: Number,
        lexeme: "8388609",
        computed_lexeme: Some(
            "8388609",
        ),
        line: 674,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 674,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 674,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 674,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 675,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 675,
    },
    Token {
        kind: Number,
        lexeme: "8388608",
        computed_lexeme: Some(
            "8388608",
        ),
        line: 675,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 675,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 675,
    },
    Token {
        kind: Number,
        lexeme: "8388608",
        computed_lexeme: Some(
            "8388608",
        ),
        line: 675,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 675,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 675,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 675,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 676,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 676,
    },
    Token {
        kind: Number,
        lexeme: "8388607",
        computed_lexeme: Some(
            "8388607",
        ),
        line: 676,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 676,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 676,
    },
    Token {
        kind: Number,
        lexeme: "8388607",
        computed_lexeme: Some(
            "8388607",
        ),
        line: 676,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 676,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 676,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 676,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 680,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: Number,
        lexeme: "3.4",
        computed_lexeme: Some(
            "3.4",
        ),
        line: 681,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 681,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 681,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: Number,
        lexeme: "3.4",
        computed_lexeme: Some(
            "3.4",
        ),
        line: 682,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 682,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 682,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: Number,
        lexeme: "3.4",
        computed_lexeme: Some(
            "3.4",
        ),
        line: 683,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 683,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 683,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: Number,
        lexeme: "3.4",
        computed_lexeme: Some(
            "3.4",
        ),
        line: 684,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 684,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 684,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 685,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 686,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 687,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 688,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 688,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 689,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 690,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 690,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 691,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 691,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 691,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 691,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 691,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 691,
    },
    Token {
        kind: Number,
        lexeme: "1e50",
        computed_lexeme: Some(
            "1e50",
        ),
        line: 691,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 691,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 691,
    },
    Token {
        kind: Number,
        lexeme: "1e50",
        computed_lexeme: Some(
            "1e50",
        ),
        line: 691,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 691,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 692,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 692,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 692,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 692,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 692,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 692,
    },
    Token {
        kind: Number,
        lexeme: "1e50",
        computed_lexeme: Some(
            "1e50",
        ),
        line: 692,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 692,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 692,
    },
    Token {
        kind: Number,
        lexeme: "1e50",
        computed_lexeme: Some(
            "1e50",
        ),
        line: 692,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 692,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: Number,
        lexeme: "1e50",
        computed_lexeme: Some(
            "1e50",
        ),
        line: 693,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: Number,
        lexeme: "1e50",
        computed_lexeme: Some(
            "1e50",
        ),
        line: 693,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 693,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: Number,
        lexeme: "1e50",
        computed_lexeme: Some(
            "1e50",
        ),
        line: 694,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: Number,
        lexeme: "1e50",
        computed_lexeme: Some(
            "1e50",
        ),
        line: 694,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 694,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: Identifier,
        lexeme: "pairs",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: Number,
        lexeme: "31",
        computed_lexeme: Some(
            "31",
        ),
        line: 695,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 695,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: Number,
        lexeme: "63",
        computed_lexeme: Some(
            "63",
        ),
        line: 695,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: Number,
        lexeme: "64",
        computed_lexeme: Some(
            "64",
        ),
        line: 695,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 695,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 696,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 696,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 696,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 697,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 697,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 697,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 697,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 698,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 698,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 698,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 699,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 699,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 699,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 699,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 700,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: String,
        lexeme: "\"number expected\"",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 701,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 702,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 702,
    },
    Token {
        kind: String,
        lexeme: "\"number expected\"",
        computed_lexeme: None,
        line: 702,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 702,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 702,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 702,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 702,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 702,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 702,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 702,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 703,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 704,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 705,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 706,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 707,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 707,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 708,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 708,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 709,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 710,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 711,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 712,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 713,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 714,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 715,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 716,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 717,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 717,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 717,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 717,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 717,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 717,
    },
    Token {
        kind: String,
        lexeme: "\"34.0\"",
        computed_lexeme: None,
        line: 717,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 717,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 717,
    },
    Token {
        kind: Number,
        lexeme: "34",
        computed_lexeme: Some(
            "34",
        ),
        line: 717,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 717,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 718,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 718,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 718,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 718,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 718,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 718,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 718,
    },
    Token {
        kind: String,
        lexeme: "\"34.3\"",
        computed_lexeme: None,
        line: 718,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 718,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 718,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 719,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 720,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 720,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 720,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 720,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 720,
    },
    Token {
        kind: Identifier,
        lexeme: "tointeger",
        computed_lexeme: None,
        line: 720,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 720,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 720,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 720,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 720,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 720,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 720,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 721,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 725,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 725,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 725,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 725,
    },
    Token {
        kind: Number,
        lexeme: "6",
        computed_lexeme: Some(
            "6",
        ),
        line: 725,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 725,
    },
    Token {
        kind: Number,
        lexeme: "6",
        computed_lexeme: Some(
            "6",
        ),
        line: 725,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 725,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 726,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 726,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 726,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 726,
    },
    Token {
        kind: Number,
        lexeme: "6",
        computed_lexeme: Some(
            "6",
        ),
        line: 726,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 726,
    },
    Token {
        kind: Number,
        lexeme: "6",
        computed_lexeme: Some(
            "6",
        ),
        line: 726,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 726,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 727,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 727,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 727,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 727,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 727,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: Identifier,
        lexeme: "mi",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: Identifier,
        lexeme: "fmod",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 728,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: Identifier,
        lexeme: "mf",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: Identifier,
        lexeme: "fmod",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 729,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 729,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 730,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 730,
    },
    Token {
        kind: Identifier,
        lexeme: "mi",
        computed_lexeme: None,
        line: 730,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 730,
    },
    Token {
        kind: Identifier,
        lexeme: "mf",
        computed_lexeme: None,
        line: 730,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 730,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: Identifier,
        lexeme: "mi",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: String,
        lexeme: "'integer'",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: Identifier,
        lexeme: "mf",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: String,
        lexeme: "'float'",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 731,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 732,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 732,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 732,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 732,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Identifier,
        lexeme: "mi",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 732,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 732,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: Identifier,
        lexeme: "mi",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: Identifier,
        lexeme: "j",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 733,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 734,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 735,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 736,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 737,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: Identifier,
        lexeme: "fmod",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 738,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 738,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: Identifier,
        lexeme: "fmod",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 739,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 739,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Identifier,
        lexeme: "fmod",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 740,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 740,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 740,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Identifier,
        lexeme: "fmod",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 741,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 741,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 741,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 743,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 743,
    },
    Token {
        kind: String,
        lexeme: "\"zero\"",
        computed_lexeme: None,
        line: 743,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 743,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 743,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 743,
    },
    Token {
        kind: Identifier,
        lexeme: "fmod",
        computed_lexeme: None,
        line: 743,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 743,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 743,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 743,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 743,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 743,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 746,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 747,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 747,
    },
    Token {
        kind: String,
        lexeme: "\"value expected\"",
        computed_lexeme: None,
        line: 747,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 747,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 747,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 747,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 747,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 747,
    },
    Token {
        kind: Identifier,
        lexeme: "checkerror",
        computed_lexeme: None,
        line: 748,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 748,
    },
    Token {
        kind: String,
        lexeme: "\"value expected\"",
        computed_lexeme: None,
        line: 748,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 748,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 748,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 748,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 748,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 748,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 749,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 749,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 749,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 750,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 750,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 750,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 750,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 750,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 750,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: Number,
        lexeme: "10e60",
        computed_lexeme: Some(
            "10e60",
        ),
        line: 751,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: Number,
        lexeme: "10e60",
        computed_lexeme: Some(
            "10e60",
        ),
        line: 751,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 751,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 752,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 752,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 752,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 753,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 753,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 753,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 754,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 754,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 754,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 754,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 754,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 754,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Number,
        lexeme: "3.2",
        computed_lexeme: Some(
            "3.2",
        ),
        line: 755,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Number,
        lexeme: "5.9",
        computed_lexeme: Some(
            "5.9",
        ),
        line: 755,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Number,
        lexeme: "9.2",
        computed_lexeme: Some(
            "9.2",
        ),
        line: 755,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 755,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Number,
        lexeme: "9.2",
        computed_lexeme: Some(
            "9.2",
        ),
        line: 755,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 755,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: Number,
        lexeme: "1.9",
        computed_lexeme: Some(
            "1.9",
        ),
        line: 756,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: Number,
        lexeme: "1.7",
        computed_lexeme: Some(
            "1.7",
        ),
        line: 756,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: Number,
        lexeme: "1.72",
        computed_lexeme: Some(
            "1.72",
        ),
        line: 756,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: Number,
        lexeme: "1.7",
        computed_lexeme: Some(
            "1.7",
        ),
        line: 756,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 756,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: Number,
        lexeme: "10e60",
        computed_lexeme: Some(
            "10e60",
        ),
        line: 757,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: Number,
        lexeme: "10e60",
        computed_lexeme: Some(
            "10e60",
        ),
        line: 757,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 757,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 758,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 758,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 758,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Identifier,
        lexeme: "eqT",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 759,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 759,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 759,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 759,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 760,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 763,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 763,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 763,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 763,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 763,
    },
    Token {
        kind: String,
        lexeme: "'10'",
        computed_lexeme: None,
        line: 763,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 763,
    },
    Token {
        kind: String,
        lexeme: "'20'",
        computed_lexeme: None,
        line: 763,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Number,
        lexeme: "200",
        computed_lexeme: Some(
            "200",
        ),
        line: 764,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Number,
        lexeme: "30",
        computed_lexeme: Some(
            "30",
        ),
        line: 764,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 764,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 764,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Number,
        lexeme: "20",
        computed_lexeme: Some(
            "20",
        ),
        line: 764,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 764,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 765,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 765,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 765,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 765,
    },
    Token {
        kind: String,
        lexeme: "'10'",
        computed_lexeme: None,
        line: 765,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 765,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 765,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 765,
    },
    Token {
        kind: String,
        lexeme: "'20'",
        computed_lexeme: None,
        line: 765,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 765,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 768,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 769,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 769,
    },
    Token {
        kind: String,
        lexeme: "\"testing -0 and NaN\"",
        computed_lexeme: None,
        line: 769,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 769,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 770,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 770,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 770,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 770,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 770,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 770,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 770,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 770,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 771,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 771,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 771,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 771,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 771,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 771,
    },
    Token {
        kind: Number,
        lexeme: "0.0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 771,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 772,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 772,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 772,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 772,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 772,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 772,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 773,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 773,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 773,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 773,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 773,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 773,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 773,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 773,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 773,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 773,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 773,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 773,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 773,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 773,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 774,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 774,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 774,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 774,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 774,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 774,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 774,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 774,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 774,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 774,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 775,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 775,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 775,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 776,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 776,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 776,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 776,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 776,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 776,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 777,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 777,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 777,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 778,
    },
    Token {
        kind: Identifier,
        lexeme: "inf",
        computed_lexeme: None,
        line: 778,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 778,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 778,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 778,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 778,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 778,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 778,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 778,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 778,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 779,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 779,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 779,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 779,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 779,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 779,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 779,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 779,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 779,
    },
    Token {
        kind: Identifier,
        lexeme: "inf",
        computed_lexeme: None,
        line: 779,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 780,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 780,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 780,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 780,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 780,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 780,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 780,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 780,
    },
    Token {
        kind: Identifier,
        lexeme: "inf",
        computed_lexeme: None,
        line: 780,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 781,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 781,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 781,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 781,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 781,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 781,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 782,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 782,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 782,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 782,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 782,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 782,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 782,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 782,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 782,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 782,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 782,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 782,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 782,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 782,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 783,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 783,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 783,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 783,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 783,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 783,
    },
    Token {
        kind: Identifier,
        lexeme: "inf",
        computed_lexeme: None,
        line: 783,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 783,
    },
    Token {
        kind: Identifier,
        lexeme: "inf",
        computed_lexeme: None,
        line: 783,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 784,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 784,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 784,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 784,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 784,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 784,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 785,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 785,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 785,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 785,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 785,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 785,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 785,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 785,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 785,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 786,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 786,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 786,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 786,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 786,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 786,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 786,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 786,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 786,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 787,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 787,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 787,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 787,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 787,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 787,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 787,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 787,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 787,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 788,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 788,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 788,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 788,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 788,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 788,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 788,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 788,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 788,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 789,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 789,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 789,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 790,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN1",
        computed_lexeme: None,
        line: 790,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 790,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 790,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 790,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 790,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 790,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 790,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 790,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN1",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN1",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN1",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 791,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 792,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 792,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 792,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 792,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 792,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: Identifier,
        lexeme: "rawset",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 793,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 793,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 794,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 794,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 794,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 794,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 794,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 794,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 794,
    },
    Token {
        kind: Identifier,
        lexeme: "undef",
        computed_lexeme: None,
        line: 794,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 794,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 795,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 795,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 795,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 795,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 795,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 795,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: Identifier,
        lexeme: "rawset",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 796,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 796,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 797,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 797,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 797,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 797,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 797,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 797,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 797,
    },
    Token {
        kind: Identifier,
        lexeme: "undef",
        computed_lexeme: None,
        line: 797,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 797,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Identifier,
        lexeme: "a1",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Identifier,
        lexeme: "a2",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Identifier,
        lexeme: "a3",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Identifier,
        lexeme: "a4",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Identifier,
        lexeme: "a5",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 800,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 800,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: String,
        lexeme: "\"\\0\\0\\0\\0\\0\\0\\0\\0\"",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 800,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: String,
        lexeme: "\"\\0\\0\\0\\0\\0\\0\\0\\0\"",
        computed_lexeme: None,
        line: 800,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: Identifier,
        lexeme: "a1",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: Identifier,
        lexeme: "a2",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: Identifier,
        lexeme: "a2",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: Identifier,
        lexeme: "a4",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: Identifier,
        lexeme: "a1",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: Identifier,
        lexeme: "a3",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 801,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 802,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 802,
    },
    Token {
        kind: Identifier,
        lexeme: "a3",
        computed_lexeme: None,
        line: 802,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 802,
    },
    Token {
        kind: Identifier,
        lexeme: "a5",
        computed_lexeme: None,
        line: 802,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 802,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 803,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 806,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 806,
    },
    Token {
        kind: String,
        lexeme: "\"testing 'math.random'\"",
        computed_lexeme: None,
        line: 806,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 806,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 808,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 810,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 810,
    },
    Token {
        kind: Identifier,
        lexeme: "testnear",
        computed_lexeme: None,
        line: 810,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 810,
    },
    Token {
        kind: Identifier,
        lexeme: "val",
        computed_lexeme: None,
        line: 810,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 810,
    },
    Token {
        kind: Identifier,
        lexeme: "ref",
        computed_lexeme: None,
        line: 810,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 810,
    },
    Token {
        kind: Identifier,
        lexeme: "tol",
        computed_lexeme: None,
        line: 810,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 810,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: Identifier,
        lexeme: "abs",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: Identifier,
        lexeme: "val",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: Identifier,
        lexeme: "ref",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: Identifier,
        lexeme: "ref",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: Identifier,
        lexeme: "tol",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 811,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 812,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 817,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 819,
    },
    Token {
        kind: Identifier,
        lexeme: "h",
        computed_lexeme: None,
        line: 819,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 819,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 819,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 819,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 819,
    },
    Token {
        kind: Number,
        lexeme: "0x7a7040a5",
        computed_lexeme: Some(
            "0x7a7040a5",
        ),
        line: 819,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 820,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 820,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 820,
    },
    Token {
        kind: Identifier,
        lexeme: "const",
        computed_lexeme: None,
        line: 820,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 820,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 820,
    },
    Token {
        kind: Number,
        lexeme: "0xa323c9d6",
        computed_lexeme: Some(
            "0xa323c9d6",
        ),
        line: 820,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 822,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 822,
    },
    Token {
        kind: Identifier,
        lexeme: "randomseed",
        computed_lexeme: None,
        line: 822,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 822,
    },
    Token {
        kind: Number,
        lexeme: "1007",
        computed_lexeme: Some(
            "1007",
        ),
        line: 822,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 822,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: Identifier,
        lexeme: "res",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: Identifier,
        lexeme: "h",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 824,
    },
    Token {
        kind: BitOr,
        lexeme: "|",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: BitAnd,
        lexeme: "&",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: Tilde,
        lexeme: "~",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: Tilde,
        lexeme: "~",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 824,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 824,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 825,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 825,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 825,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 825,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 825,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 825,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 825,
    },
    Token {
        kind: Identifier,
        lexeme: "res",
        computed_lexeme: None,
        line: 825,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 825,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 827,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 827,
    },
    Token {
        kind: Identifier,
        lexeme: "randomseed",
        computed_lexeme: None,
        line: 827,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 827,
    },
    Token {
        kind: Number,
        lexeme: "1007",
        computed_lexeme: Some(
            "1007",
        ),
        line: 827,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 827,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 827,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 827,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 830,
    },
    Token {
        kind: Identifier,
        lexeme: "res",
        computed_lexeme: None,
        line: 830,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 831,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 831,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 831,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 831,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 831,
    },
    Token {
        kind: Identifier,
        lexeme: "res",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: Identifier,
        lexeme: "h",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: BitShiftRight,
        lexeme: ">>",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 833,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 833,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 833,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 833,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 834,
    },
    Token {
        kind: Identifier,
        lexeme: "res",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Identifier,
        lexeme: "h",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 836,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 836,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 836,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 836,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: BitShiftRight,
        lexeme: ">>",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Number,
        lexeme: "64",
        computed_lexeme: Some(
            "64",
        ),
        line: 836,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 836,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 836,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 836,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 837,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 838,
    },
    Token {
        kind: Identifier,
        lexeme: "rand",
        computed_lexeme: None,
        line: 838,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 838,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 838,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 838,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 838,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: Identifier,
        lexeme: "rand",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: Number,
        lexeme: "0x0.7a7040a5a323c9d6",
        computed_lexeme: Some(
            "0.4782753376376966",
        ),
        line: 839,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 839,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 839,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 840,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 840,
    },
    Token {
        kind: Identifier,
        lexeme: "rand",
        computed_lexeme: None,
        line: 840,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 840,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 840,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 840,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 840,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 840,
    },
    Token {
        kind: Identifier,
        lexeme: "res",
        computed_lexeme: None,
        line: 840,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 840,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 841,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 843,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 845,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 845,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 845,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 845,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 845,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 845,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 845,
    },
    Token {
        kind: Identifier,
        lexeme: "randomseed",
        computed_lexeme: None,
        line: 845,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 845,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 845,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 846,
    },
    Token {
        kind: Identifier,
        lexeme: "res",
        computed_lexeme: None,
        line: 846,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 846,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 846,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 846,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 846,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 846,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 846,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 846,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: Identifier,
        lexeme: "randomseed",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 847,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 848,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 848,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 848,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 848,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 848,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 848,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 848,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 848,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 848,
    },
    Token {
        kind: Identifier,
        lexeme: "res",
        computed_lexeme: None,
        line: 848,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 848,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 849,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 849,
    },
    Token {
        kind: Identifier,
        lexeme: "randomseed",
        computed_lexeme: None,
        line: 849,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 849,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 849,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 849,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 849,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 849,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 850,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 850,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 850,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 850,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 850,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 850,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 850,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 850,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 850,
    },
    Token {
        kind: Identifier,
        lexeme: "res",
        computed_lexeme: None,
        line: 850,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 850,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: String,
        lexeme: "\"random seeds: %d, %d\"",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 852,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 853,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 855,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 856,
    },
    Token {
        kind: Identifier,
        lexeme: "randbits",
        computed_lexeme: None,
        line: 856,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 856,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 856,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 856,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 856,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 856,
    },
    Token {
        kind: Identifier,
        lexeme: "floatbits",
        computed_lexeme: None,
        line: 856,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 856,
    },
    Token {
        kind: Number,
        lexeme: "64",
        computed_lexeme: Some(
            "64",
        ),
        line: 856,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 856,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 857,
    },
    Token {
        kind: Identifier,
        lexeme: "mult",
        computed_lexeme: None,
        line: 857,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 857,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 857,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 857,
    },
    Token {
        kind: Identifier,
        lexeme: "randbits",
        computed_lexeme: None,
        line: 857,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 858,
    },
    Token {
        kind: Identifier,
        lexeme: "counts",
        computed_lexeme: None,
        line: 858,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 858,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 858,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 858,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 859,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: Identifier,
        lexeme: "randbits",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: Identifier,
        lexeme: "counts",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 859,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 859,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 860,
    },
    Token {
        kind: Identifier,
        lexeme: "up",
        computed_lexeme: None,
        line: 860,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 860,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 860,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 860,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 860,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 860,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 861,
    },
    Token {
        kind: Identifier,
        lexeme: "low",
        computed_lexeme: None,
        line: 861,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 861,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 861,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 861,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 861,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 862,
    },
    Token {
        kind: Identifier,
        lexeme: "rounds",
        computed_lexeme: None,
        line: 862,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 862,
    },
    Token {
        kind: Number,
        lexeme: "100",
        computed_lexeme: Some(
            "100",
        ),
        line: 862,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 862,
    },
    Token {
        kind: Identifier,
        lexeme: "randbits",
        computed_lexeme: None,
        line: 862,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 863,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrounds",
        computed_lexeme: None,
        line: 863,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 863,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 863,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 865,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 865,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 865,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 865,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 865,
    },
    Token {
        kind: Identifier,
        lexeme: "rounds",
        computed_lexeme: None,
        line: 865,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 865,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 866,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 866,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 866,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 866,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 866,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 866,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 867,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 867,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 867,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 867,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 867,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 867,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 867,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 867,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 867,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 867,
    },
    Token {
        kind: Identifier,
        lexeme: "up",
        computed_lexeme: None,
        line: 868,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 868,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 868,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 868,
    },
    Token {
        kind: Identifier,
        lexeme: "up",
        computed_lexeme: None,
        line: 868,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 868,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 868,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 868,
    },
    Token {
        kind: Identifier,
        lexeme: "low",
        computed_lexeme: None,
        line: 869,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 869,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 869,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 869,
    },
    Token {
        kind: Identifier,
        lexeme: "low",
        computed_lexeme: None,
        line: 869,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 869,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 869,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 869,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 870,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 870,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 870,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 870,
    },
    Token {
        kind: Identifier,
        lexeme: "mult",
        computed_lexeme: None,
        line: 870,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 870,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 870,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 870,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 870,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 870,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 871,
    },
    Token {
        kind: Identifier,
        lexeme: "bit",
        computed_lexeme: None,
        line: 871,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 871,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 871,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 871,
    },
    Token {
        kind: Identifier,
        lexeme: "randbits",
        computed_lexeme: None,
        line: 871,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 872,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 872,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 872,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 872,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 872,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 872,
    },
    Token {
        kind: Identifier,
        lexeme: "bit",
        computed_lexeme: None,
        line: 872,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 872,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 872,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 872,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 872,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 872,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 872,
    },
    Token {
        kind: Identifier,
        lexeme: "counts",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: Identifier,
        lexeme: "bit",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 873,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: Identifier,
        lexeme: "counts",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: Identifier,
        lexeme: "bit",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 873,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 873,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 873,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 874,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 875,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrounds",
        computed_lexeme: None,
        line: 876,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 876,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrounds",
        computed_lexeme: None,
        line: 876,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 876,
    },
    Token {
        kind: Identifier,
        lexeme: "rounds",
        computed_lexeme: None,
        line: 876,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Identifier,
        lexeme: "up",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 877,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Number,
        lexeme: "0.001",
        computed_lexeme: Some(
            "0.001",
        ),
        line: 877,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Identifier,
        lexeme: "low",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 877,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Number,
        lexeme: "0.001",
        computed_lexeme: Some(
            "0.001",
        ),
        line: 877,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 877,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 879,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 881,
    },
    Token {
        kind: Identifier,
        lexeme: "expected",
        computed_lexeme: None,
        line: 881,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 881,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 881,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrounds",
        computed_lexeme: None,
        line: 881,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 881,
    },
    Token {
        kind: Identifier,
        lexeme: "randbits",
        computed_lexeme: None,
        line: 881,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 881,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 881,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 881,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 882,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 882,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 882,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 882,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 882,
    },
    Token {
        kind: Identifier,
        lexeme: "randbits",
        computed_lexeme: None,
        line: 882,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 882,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: Identifier,
        lexeme: "testnear",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: Identifier,
        lexeme: "counts",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: Identifier,
        lexeme: "expected",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: Number,
        lexeme: "0.10",
        computed_lexeme: Some(
            "0.10",
        ),
        line: 883,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 883,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 885,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 886,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 887,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 887,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 887,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 887,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 887,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 887,
    },
    Token {
        kind: String,
        lexeme: "\"float random range in %d calls: [%f, %f]\"",
        computed_lexeme: None,
        line: 887,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 887,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrounds",
        computed_lexeme: None,
        line: 888,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 888,
    },
    Token {
        kind: Identifier,
        lexeme: "low",
        computed_lexeme: None,
        line: 888,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 888,
    },
    Token {
        kind: Identifier,
        lexeme: "up",
        computed_lexeme: None,
        line: 888,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 888,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 888,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 889,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 892,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 893,
    },
    Token {
        kind: Identifier,
        lexeme: "up",
        computed_lexeme: None,
        line: 893,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 893,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 893,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 894,
    },
    Token {
        kind: Identifier,
        lexeme: "low",
        computed_lexeme: None,
        line: 894,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 894,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 894,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 895,
    },
    Token {
        kind: Identifier,
        lexeme: "counts",
        computed_lexeme: None,
        line: 895,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 895,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 895,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 895,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 896,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: Identifier,
        lexeme: "counts",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 896,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 896,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 897,
    },
    Token {
        kind: Identifier,
        lexeme: "rounds",
        computed_lexeme: None,
        line: 897,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 897,
    },
    Token {
        kind: Number,
        lexeme: "100",
        computed_lexeme: Some(
            "100",
        ),
        line: 897,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 897,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 897,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 898,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrounds",
        computed_lexeme: None,
        line: 898,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 898,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 898,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 900,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 900,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 900,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 900,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 900,
    },
    Token {
        kind: Identifier,
        lexeme: "rounds",
        computed_lexeme: None,
        line: 900,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 900,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 901,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 901,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 901,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 901,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 901,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 901,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 901,
    },
    Token {
        kind: Identifier,
        lexeme: "up",
        computed_lexeme: None,
        line: 902,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 902,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 902,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 902,
    },
    Token {
        kind: Identifier,
        lexeme: "up",
        computed_lexeme: None,
        line: 902,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 902,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 902,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 902,
    },
    Token {
        kind: Identifier,
        lexeme: "low",
        computed_lexeme: None,
        line: 903,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 903,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 903,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 903,
    },
    Token {
        kind: Identifier,
        lexeme: "low",
        computed_lexeme: None,
        line: 903,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 903,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 903,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 903,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 904,
    },
    Token {
        kind: Identifier,
        lexeme: "bit",
        computed_lexeme: None,
        line: 904,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 904,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 904,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 904,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 904,
    },
    Token {
        kind: Identifier,
        lexeme: "counts",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Identifier,
        lexeme: "bit",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 906,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Identifier,
        lexeme: "counts",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Identifier,
        lexeme: "bit",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 906,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: BitShiftRight,
        lexeme: ">>",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Identifier,
        lexeme: "bit",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: BitAnd,
        lexeme: "&",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 906,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 906,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 907,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrounds",
        computed_lexeme: None,
        line: 908,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 908,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrounds",
        computed_lexeme: None,
        line: 908,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 908,
    },
    Token {
        kind: Identifier,
        lexeme: "rounds",
        computed_lexeme: None,
        line: 908,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 909,
    },
    Token {
        kind: Identifier,
        lexeme: "lim",
        computed_lexeme: None,
        line: 909,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 909,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 909,
    },
    Token {
        kind: BitShiftRight,
        lexeme: ">>",
        computed_lexeme: None,
        line: 909,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 909,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: Identifier,
        lexeme: "up",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: Identifier,
        lexeme: "lim",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: Identifier,
        lexeme: "low",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: Identifier,
        lexeme: "lim",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 910,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 912,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 914,
    },
    Token {
        kind: Identifier,
        lexeme: "expected",
        computed_lexeme: None,
        line: 914,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 914,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 914,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrounds",
        computed_lexeme: None,
        line: 914,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 914,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 914,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 914,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 914,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 914,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 915,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 915,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 915,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 915,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 915,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 915,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 915,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: Identifier,
        lexeme: "testnear",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: Identifier,
        lexeme: "counts",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: Identifier,
        lexeme: "expected",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: Number,
        lexeme: "0.10",
        computed_lexeme: Some(
            "0.10",
        ),
        line: 916,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 916,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 918,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 919,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 920,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 920,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 920,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 920,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 920,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 920,
    },
    Token {
        kind: String,
        lexeme: "\"integer random range in %d calls: [minint + %.0fppm, maxint - %.0fppm]\"",
        computed_lexeme: None,
        line: 921,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 921,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrounds",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: Identifier,
        lexeme: "low",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: Number,
        lexeme: "1e6",
        computed_lexeme: Some(
            "1e6",
        ),
        line: 922,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 922,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 923,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 923,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 923,
    },
    Token {
        kind: Identifier,
        lexeme: "up",
        computed_lexeme: None,
        line: 923,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 923,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 923,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 923,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 923,
    },
    Token {
        kind: Number,
        lexeme: "1e6",
        computed_lexeme: Some(
            "1e6",
        ),
        line: 923,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 923,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 923,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 924,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 926,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 928,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 928,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 928,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 928,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 928,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 928,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 928,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 928,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 928,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 928,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 928,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 928,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 928,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 928,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 928,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 928,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 929,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 929,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 929,
    },
    Token {
        kind: Number,
        lexeme: "200",
        computed_lexeme: Some(
            "200",
        ),
        line: 929,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 930,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrep",
        computed_lexeme: None,
        line: 930,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 930,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 930,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 932,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 932,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 932,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 932,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 932,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 932,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 932,
    },
    Token {
        kind: Number,
        lexeme: "6",
        computed_lexeme: Some(
            "6",
        ),
        line: 932,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 932,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 933,
    },
    Token {
        kind: Identifier,
        lexeme: "r",
        computed_lexeme: None,
        line: 933,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 933,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 933,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 933,
    },
    Token {
        kind: Number,
        lexeme: "6",
        computed_lexeme: Some(
            "6",
        ),
        line: 933,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 933,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 934,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 934,
    },
    Token {
        kind: Identifier,
        lexeme: "r",
        computed_lexeme: None,
        line: 934,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 934,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 934,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 934,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 934,
    },
    Token {
        kind: Identifier,
        lexeme: "r",
        computed_lexeme: None,
        line: 934,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 934,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 934,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 934,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 935,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrep",
        computed_lexeme: None,
        line: 936,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 936,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrep",
        computed_lexeme: None,
        line: 936,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 936,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 936,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 937,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 937,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 937,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 937,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 937,
    },
    Token {
        kind: Number,
        lexeme: "6",
        computed_lexeme: Some(
            "6",
        ),
        line: 937,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 937,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: Identifier,
        lexeme: "testnear",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: Identifier,
        lexeme: "totalrep",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: Number,
        lexeme: "0.05",
        computed_lexeme: Some(
            "0.05",
        ),
        line: 938,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 938,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 940,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 941,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 942,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 944,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 945,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 945,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 945,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 945,
    },
    Token {
        kind: Identifier,
        lexeme: "x1",
        computed_lexeme: None,
        line: 945,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 945,
    },
    Token {
        kind: Identifier,
        lexeme: "x2",
        computed_lexeme: None,
        line: 945,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 945,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 946,
    },
    Token {
        kind: Identifier,
        lexeme: "mark",
        computed_lexeme: None,
        line: 946,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 946,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 946,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 946,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 946,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 946,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 946,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 946,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 946,
    },
    Token {
        kind: While,
        lexeme: "while",
        computed_lexeme: None,
        line: 947,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 947,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 947,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 948,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 948,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 948,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 948,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 948,
    },
    Token {
        kind: Identifier,
        lexeme: "x1",
        computed_lexeme: None,
        line: 948,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 948,
    },
    Token {
        kind: Identifier,
        lexeme: "x2",
        computed_lexeme: None,
        line: 948,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 948,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 949,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 949,
    },
    Token {
        kind: Identifier,
        lexeme: "x1",
        computed_lexeme: None,
        line: 949,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 949,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 949,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 949,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 949,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 949,
    },
    Token {
        kind: Identifier,
        lexeme: "x2",
        computed_lexeme: None,
        line: 949,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 949,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 950,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 950,
    },
    Token {
        kind: Identifier,
        lexeme: "mark",
        computed_lexeme: None,
        line: 950,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 950,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 950,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 950,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 950,
    },
    Token {
        kind: Identifier,
        lexeme: "mark",
        computed_lexeme: None,
        line: 951,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 951,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 951,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 951,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 951,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 951,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 952,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 952,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 952,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 952,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 952,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 953,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 953,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 953,
    },
    Token {
        kind: Identifier,
        lexeme: "x2",
        computed_lexeme: None,
        line: 953,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 953,
    },
    Token {
        kind: Identifier,
        lexeme: "x1",
        computed_lexeme: None,
        line: 953,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 953,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 953,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 953,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 955,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 956,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 957,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 958,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 960,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 960,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 960,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 960,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 960,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 960,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 960,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 961,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 961,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 961,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 961,
    },
    Token {
        kind: Number,
        lexeme: "6",
        computed_lexeme: Some(
            "6",
        ),
        line: 961,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 961,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 962,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 962,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 962,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 962,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 962,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 962,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 963,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 963,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 963,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 963,
    },
    Token {
        kind: Number,
        lexeme: "13",
        computed_lexeme: Some(
            "13",
        ),
        line: 963,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 963,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 964,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 964,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 964,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 964,
    },
    Token {
        kind: Number,
        lexeme: "31",
        computed_lexeme: Some(
            "31",
        ),
        line: 964,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 964,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 965,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 965,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 965,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 965,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 965,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 965,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 966,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 966,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 966,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 966,
    },
    Token {
        kind: Number,
        lexeme: "33",
        computed_lexeme: Some(
            "33",
        ),
        line: 966,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 966,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 967,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 967,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 967,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 967,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 967,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 967,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 967,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 968,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 968,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 968,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 968,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 968,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 968,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 968,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 968,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 969,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 969,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 969,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 969,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 969,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 969,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 970,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 970,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 970,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 970,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 970,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 970,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 971,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 971,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 971,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 971,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 971,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 971,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 971,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 971,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 972,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 972,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 972,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 972,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 972,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 972,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 972,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 972,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 973,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 975,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 976,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 976,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 976,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 976,
    },
    Token {
        kind: Identifier,
        lexeme: "p1",
        computed_lexeme: None,
        line: 976,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 976,
    },
    Token {
        kind: Identifier,
        lexeme: "p2",
        computed_lexeme: None,
        line: 976,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 976,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 977,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 977,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 977,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 977,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 978,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 978,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 978,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 978,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 979,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 979,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 979,
    },
    Token {
        kind: Number,
        lexeme: "100",
        computed_lexeme: Some(
            "100",
        ),
        line: 979,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 980,
    },
    Token {
        kind: Identifier,
        lexeme: "mark",
        computed_lexeme: None,
        line: 980,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 980,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 980,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 980,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 980,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 980,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 980,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 980,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 980,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 982,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 982,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 982,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 982,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 982,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 982,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 982,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 983,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 983,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 983,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 983,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 983,
    },
    Token {
        kind: Identifier,
        lexeme: "p1",
        computed_lexeme: None,
        line: 983,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 983,
    },
    Token {
        kind: Identifier,
        lexeme: "p2",
        computed_lexeme: None,
        line: 983,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 983,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 984,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 984,
    },
    Token {
        kind: Identifier,
        lexeme: "mark",
        computed_lexeme: None,
        line: 984,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 984,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 984,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 984,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 984,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 985,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 985,
    },
    Token {
        kind: Identifier,
        lexeme: "p1",
        computed_lexeme: None,
        line: 985,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 985,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 985,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 985,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 985,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 985,
    },
    Token {
        kind: Identifier,
        lexeme: "p2",
        computed_lexeme: None,
        line: 985,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 985,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 986,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 986,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 986,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 986,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 986,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 986,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 986,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 986,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 986,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 986,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 987,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 987,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 987,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 987,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 987,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 987,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 987,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 987,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 987,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 987,
    },
    Token {
        kind: Identifier,
        lexeme: "mark",
        computed_lexeme: None,
        line: 988,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 988,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 988,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 988,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 988,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 988,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 989,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 989,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 989,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 989,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 989,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 990,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 991,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 993,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 993,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 993,
    },
    Token {
        kind: Identifier,
        lexeme: "count",
        computed_lexeme: None,
        line: 993,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 993,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 993,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 993,
    },
    Token {
        kind: Number,
        lexeme: "0.8",
        computed_lexeme: Some(
            "0.8",
        ),
        line: 993,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 993,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 993,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 995,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 997,
    },
    Token {
        kind: Identifier,
        lexeme: "diff",
        computed_lexeme: None,
        line: 997,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 997,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 997,
    },
    Token {
        kind: Identifier,
        lexeme: "p2",
        computed_lexeme: None,
        line: 997,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 997,
    },
    Token {
        kind: Identifier,
        lexeme: "p1",
        computed_lexeme: None,
        line: 997,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 997,
    },
    Token {
        kind: BitShiftRight,
        lexeme: ">>",
        computed_lexeme: None,
        line: 997,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 997,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: Identifier,
        lexeme: "p1",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: Identifier,
        lexeme: "diff",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: Identifier,
        lexeme: "p2",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: Identifier,
        lexeme: "diff",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 998,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 1000,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 1001,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 1002,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1002,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 1002,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1002,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 1002,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1002,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 1003,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1003,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 1003,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1003,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 1003,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1003,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 1004,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1004,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 1004,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1004,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 1004,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 1004,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 1004,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1004,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 1005,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1005,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 1005,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1005,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 1005,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 1005,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1005,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 1006,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1006,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 1006,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 1006,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 1006,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1006,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 1006,
    },
    Token {
        kind: FloorDiv,
        lexeme: "//",
        computed_lexeme: None,
        line: 1006,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 1006,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1006,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 1007,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1007,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 1007,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1007,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 1007,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1007,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 1008,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1008,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 1008,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 1008,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 1008,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1008,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 1008,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1008,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 1009,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1009,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 1009,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1009,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 1009,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 1009,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 1009,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1009,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 1010,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1010,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 1010,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1010,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 1010,
    },
    Token {
        kind: BitShiftLeft,
        lexeme: "<<",
        computed_lexeme: None,
        line: 1010,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1010,
    },
    Token {
        kind: Identifier,
        lexeme: "intbits",
        computed_lexeme: None,
        line: 1010,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 1010,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 1010,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1010,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1010,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 1011,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 1014,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 1014,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 1014,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1014,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 1017,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1017,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 1018,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1018,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: Identifier,
        lexeme: "maxint",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: Identifier,
        lexeme: "minint",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1019,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 1023,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1023,
    },
    Token {
        kind: String,
        lexeme: "'OK'",
        computed_lexeme: None,
        line: 1023,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1023,
    },
]
