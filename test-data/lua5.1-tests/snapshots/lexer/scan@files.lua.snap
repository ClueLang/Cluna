---
source: src/main.rs
expression: scanned
input_file: test-data/lua5.1-tests/files.lua
---
[
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: String,
        lexeme: "'testing i/o'",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Identifier,
        lexeme: "stdin",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Identifier,
        lexeme: "stdin",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Identifier,
        lexeme: "stdout",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Identifier,
        lexeme: "stdout",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 4,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: String,
        lexeme: "\"userdata\"",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: String,
        lexeme: "\"file\"",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Number,
        lexeme: "8",
        computed_lexeme: Some(
            "8",
        ),
        line: 8,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "setmetatable",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: String,
        lexeme: "'xuxu_nao_existe'",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: String,
        lexeme: "\"string\"",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: String,
        lexeme: "\"number\"",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: String,
        lexeme: "'/a/b/c/d'",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: String,
        lexeme: "'w'",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: String,
        lexeme: "\"string\"",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: String,
        lexeme: "\"number\"",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Identifier,
        lexeme: "tmpname",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Identifier,
        lexeme: "tmpname",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Identifier,
        lexeme: "setlocale",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: String,
        lexeme: "'C'",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: String,
        lexeme: "'all'",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Identifier,
        lexeme: "stdin",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "stdout",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Identifier,
        lexeme: "loadfile",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Identifier,
        lexeme: "stdout",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 33,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: String,
        lexeme: "\"alo alo\"",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: String,
        lexeme: "\"alo alo\"",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: String,
        lexeme: "\"cur\"",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 36,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: String,
        lexeme: "\"alo alo\"",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 36,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: String,
        lexeme: "\"joao\"",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: String,
        lexeme: "\"end\"",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: String,
        lexeme: "\"alo joao\"",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: String,
        lexeme: "\"set\"",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 40,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: String,
        lexeme: "'\"�lo\"'",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: String,
        lexeme: "\"{a}\\n\"",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: String,
        lexeme: "\"second line\\n\"",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: String,
        lexeme: "\"third line \\n\"",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: String,
        lexeme: "'�fourth_line'",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Identifier,
        lexeme: "stdout",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "stdin",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "rawequal",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "stdout",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 46,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: String,
        lexeme: "'+'",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 47,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 51,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Number,
        lexeme: "120",
        computed_lexeme: Some(
            "120",
        ),
        line: 51,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 52,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 52,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: String,
        lexeme: "'r'",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Identifier,
        lexeme: "lines",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 57,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 57,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 57,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "rename",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Identifier,
        lexeme: "rename",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: String,
        lexeme: "\"a\"",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\\n\\t\\t  3450\\n\"",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Identifier,
        lexeme: "rename",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Identifier,
        lexeme: "lines",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: While,
        lexeme: "while",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "lines",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\"",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: String,
        lexeme: "\"file\"",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "lines",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\"",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "tostring",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: String,
        lexeme: "\"file (closed)\"",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: String,
        lexeme: "\"closed file\"",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Identifier,
        lexeme: "lines",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "lines",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 94,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: String,
        lexeme: "\"xuxu\"",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: String,
        lexeme: "\"string\"",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: String,
        lexeme: "\"number\"",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 98,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 99,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: String,
        lexeme: "'*l'",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: String,
        lexeme: "'\"�lo\"'",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 100,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: String,
        lexeme: "\"second line\"",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: String,
        lexeme: "\"third line \"",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: String,
        lexeme: "\"set\"",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 104,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: String,
        lexeme: "'*l'",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: String,
        lexeme: "\"third line \"",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 106,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: String,
        lexeme: "\"�\"",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: String,
        lexeme: "\"fourth_line\"",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: String,
        lexeme: "\"fourth_line\"",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 107,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: String,
        lexeme: "\"cur\"",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: String,
        lexeme: "\"fourth_line\"",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: String,
        lexeme: "\"fourth_line\"",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: String,
        lexeme: "'*n'",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Number,
        lexeme: "3450",
        computed_lexeme: Some(
            "3450",
        ),
        line: 111,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: String,
        lexeme: "'\\n'",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 113,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 114,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 115,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 115,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 116,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 117,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 117,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: String,
        lexeme: "'*n'",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 118,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: String,
        lexeme: "'*n'",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 119,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 119,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: String,
        lexeme: "'*a'",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: String,
        lexeme: "''",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: String,
        lexeme: "'*a'",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: String,
        lexeme: "''",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: String,
        lexeme: "'+'",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 127,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: String,
        lexeme: "'0123456789'",
        computed_lexeme: None,
        line: 129,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 130,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Number,
        lexeme: "12",
        computed_lexeme: Some(
            "12",
        ),
        line: 130,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 130,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 131,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 131,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Number,
        lexeme: "12",
        computed_lexeme: Some(
            "12",
        ),
        line: 131,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 131,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: String,
        lexeme: "\"alo\\n\"",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: String,
        lexeme: "\"a\"",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: String,
        lexeme: "' '",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: String,
        lexeme: "' '",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: String,
        lexeme: "';'",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: String,
        lexeme: "'end of file\\n'",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "flush",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 143,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Identifier,
        lexeme: "flush",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 144,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: String,
        lexeme: "'+'",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 148,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: String,
        lexeme: "\"alo\"",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 150,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: String,
        lexeme: "' '",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 151,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 152,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: String,
        lexeme: "' '",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 153,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: String,
        lexeme: "'*a'",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: String,
        lexeme: "';end of file\\n'",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 155,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 156,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 158,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: String,
        lexeme: "'+'",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "x1",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: String,
        lexeme: "\"string\\n\\n\\\\com \\\"\\\"''coisas [[estranhas]] ]]'\"",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: String,
        lexeme: "\"x2 = %q\\n-- comment without ending EOS\"",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Identifier,
        lexeme: "x1",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 163,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "loadfile",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Identifier,
        lexeme: "x1",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Identifier,
        lexeme: "x2",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: String,
        lexeme: "'+'",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 172,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: String,
        lexeme: "\"qualquer coisa\\n\"",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 173,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: String,
        lexeme: "\"mais qualquer coisa\"",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: String,
        lexeme: "'wb'",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: String,
        lexeme: "\"outra coisa\\0\\1\\3\\0\\0\\0\\0\\255\\0\"",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 178,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Identifier,
        lexeme: "filehandle",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: String,
        lexeme: "'r'",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfilehandle",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: String,
        lexeme: "'rb'",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: Identifier,
        lexeme: "filehandle",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfilehandle",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "filehandle",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: String,
        lexeme: "\"userdata\"",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "filehandle",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: String,
        lexeme: "'*l'",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: String,
        lexeme: "\"qualquer coisa\"",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfilehandle",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: String,
        lexeme: "\"outra coisa\"",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: String,
        lexeme: "\"outra coisa\"",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "filehandle",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: String,
        lexeme: "'*l'",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: String,
        lexeme: "\"mais qualquer coisa\"",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "filehandle",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Identifier,
        lexeme: "filehandle",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: String,
        lexeme: "\"userdata\"",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfilehandle",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 191,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: String,
        lexeme: "\"\\0\\1\\3\\0\"",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 192,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: String,
        lexeme: "\"\\0\\0\\0\"",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 193,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 194,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: String,
        lexeme: "\"\\255\"",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: String,
        lexeme: "'*a'",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: String,
        lexeme: "\"\\0\"",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 196,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfilehandle",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfilehandle",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "otherfile",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 204,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\n 123.4\t-56e-2  not a number\nsecond line\nthird line\n\nand the rest of the file\n]]",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "d",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "e",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "h",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "__",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: String,
        lexeme: "'*n'",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: String,
        lexeme: "'*n'",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: String,
        lexeme: "'*l'",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: String,
        lexeme: "'*l'",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: String,
        lexeme: "'*l'",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: String,
        lexeme: "'*a'",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 213,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: String,
        lexeme: "' '",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Identifier,
        lexeme: "__",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: String,
        lexeme: "'number'",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Number,
        lexeme: "123.4",
        computed_lexeme: Some(
            "123.4",
        ),
        line: 216,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Number,
        lexeme: "56e-2",
        computed_lexeme: Some(
            "56e-2",
        ),
        line: 216,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "d",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: String,
        lexeme: "'second line'",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "e",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: String,
        lexeme: "'third line'",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "h",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\n\nand the rest of the file\n]]",
        computed_lexeme: None,
        line: 221,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 221,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Identifier,
        lexeme: "collectgarbage",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: String,
        lexeme: "\"w\"",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: String,
        lexeme: "\"r\"",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Identifier,
        lexeme: "setvbuf",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: String,
        lexeme: "\"full\"",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Number,
        lexeme: "2000",
        computed_lexeme: Some(
            "2000",
        ),
        line: 229,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: String,
        lexeme: "\"x\"",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: String,
        lexeme: "\"*all\"",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: String,
        lexeme: "\"set\"",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: String,
        lexeme: "\"*all\"",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: String,
        lexeme: "\"x\"",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: String,
        lexeme: "\"w\"",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "setvbuf",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: String,
        lexeme: "\"no\"",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: String,
        lexeme: "\"x\"",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: String,
        lexeme: "\"set\"",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: String,
        lexeme: "\"*all\"",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: String,
        lexeme: "\"x\"",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "open",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: String,
        lexeme: "\"a\"",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "setvbuf",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: String,
        lexeme: "\"line\"",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: String,
        lexeme: "\"x\"",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: String,
        lexeme: "\"set\"",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 244,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: String,
        lexeme: "\"*all\"",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: String,
        lexeme: "\"a\\n\"",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: String,
        lexeme: "\"set\"",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 247,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 247,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: String,
        lexeme: "\"*all\"",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: String,
        lexeme: "\"xa\\n\"",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "fr",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 256,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Number,
        lexeme: "5001",
        computed_lexeme: Some(
            "5001",
        ),
        line: 256,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: String,
        lexeme: "'0123456789123'",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: String,
        lexeme: "'\\n12346'",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: String,
        lexeme: "'*a'",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: String,
        lexeme: "'set'",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 261,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Number,
        lexeme: "30001",
        computed_lexeme: Some(
            "30001",
        ),
        line: 262,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Number,
        lexeme: "1005",
        computed_lexeme: Some(
            "1005",
        ),
        line: 262,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 262,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 262,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Number,
        lexeme: "100003",
        computed_lexeme: Some(
            "100003",
        ),
        line: 262,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Number,
        lexeme: "5001",
        computed_lexeme: Some(
            "5001",
        ),
        line: 263,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Number,
        lexeme: "13",
        computed_lexeme: Some(
            "13",
        ),
        line: 263,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Number,
        lexeme: "6",
        computed_lexeme: Some(
            "6",
        ),
        line: 263,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "seek",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: String,
        lexeme: "'set'",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 264,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: String,
        lexeme: "'\\n'",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Identifier,
        lexeme: "input",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Identifier,
        lexeme: "remove",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Identifier,
        lexeme: "file",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 269,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 270,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 270,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 270,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 270,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Identifier,
        lexeme: "popen",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: String,
        lexeme: "\"ls\"",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 273,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Identifier,
        lexeme: "read",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: String,
        lexeme: "\"*a\"",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Colon,
        lexeme: ":",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Identifier,
        lexeme: "close",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 277,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Identifier,
        lexeme: "Message",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: String,
        lexeme: "'\\a\\n >>> popen not available<<<\\n\\a'",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: String,
        lexeme: "'+'",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 283,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: String,
        lexeme: "\"*t\"",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: Identifier,
        lexeme: "loadstring",
        computed_lexeme: None,
        line: 285,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 285,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 285,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 285,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 285,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 285,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[assert(T.year==%Y and T.month==%m and T.day==%d and\n  T.hour==%H and T.min==%M and T.sec==%S and\n  T.wday==%w+1 and T.yday==%j and type(T.isdst) == 'boolean')]]",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 287,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 289,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: String,
        lexeme: "\"!*t\"",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 291,
    },
    Token {
        kind: Identifier,
        lexeme: "loadstring",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 292,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[!assert(T.year==%Y and T.month==%m and T.day==%d and\n  T.hour==%H and T.min==%M and T.sec==%S and\n  T.wday==%w+1 and T.yday==%j and type(T.isdst) == 'boolean')]]",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 294,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 296,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 297,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 297,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 297,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 297,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 297,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 297,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 297,
    },
    Token {
        kind: String,
        lexeme: "\"*t\"",
        computed_lexeme: None,
        line: 297,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 297,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 298,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 298,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 298,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 298,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 298,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 298,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 298,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 298,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 298,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Identifier,
        lexeme: "isdst",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: String,
        lexeme: "'boolean'",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 299,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Identifier,
        lexeme: "isdst",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 300,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Identifier,
        lexeme: "t1",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 301,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: Identifier,
        lexeme: "t1",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 302,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 303,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 305,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 305,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 305,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 305,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 305,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 305,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 305,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 305,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Identifier,
        lexeme: "year",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Identifier,
        lexeme: "year",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 306,
    },
    Token {
        kind: Semicolon,
        lexeme: ";",
        computed_lexeme: None,
        line: 306,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Identifier,
        lexeme: "t1",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Identifier,
        lexeme: "T",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 307,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "abs",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "difftime",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "t1",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Number,
        lexeme: "24",
        computed_lexeme: Some(
            "24",
        ),
        line: 309,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Number,
        lexeme: "3600",
        computed_lexeme: Some(
            "3600",
        ),
        line: 309,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Number,
        lexeme: "365",
        computed_lexeme: Some(
            "365",
        ),
        line: 309,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 309,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 309,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 311,
    },
    Token {
        kind: Identifier,
        lexeme: "t1",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: String,
        lexeme: "\"*t\"",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 312,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Identifier,
        lexeme: "difftime",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Identifier,
        lexeme: "t1",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 313,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 313,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "t1",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "year",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Number,
        lexeme: "2000",
        computed_lexeme: Some(
            "2000",
        ),
        line: 315,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "month",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 315,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "day",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 315,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "hour",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Number,
        lexeme: "23",
        computed_lexeme: Some(
            "23",
        ),
        line: 315,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Number,
        lexeme: "12",
        computed_lexeme: Some(
            "12",
        ),
        line: 315,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Identifier,
        lexeme: "sec",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Number,
        lexeme: "17",
        computed_lexeme: Some(
            "17",
        ),
        line: 315,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 315,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "t2",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "time",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "year",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Number,
        lexeme: "2000",
        computed_lexeme: Some(
            "2000",
        ),
        line: 316,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "month",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 316,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "day",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 316,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "hour",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Number,
        lexeme: "23",
        computed_lexeme: Some(
            "23",
        ),
        line: 316,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 316,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "sec",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Number,
        lexeme: "19",
        computed_lexeme: Some(
            "19",
        ),
        line: 316,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 316,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Identifier,
        lexeme: "difftime",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Identifier,
        lexeme: "t1",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Identifier,
        lexeme: "t2",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Number,
        lexeme: "60",
        computed_lexeme: Some(
            "60",
        ),
        line: 317,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 317,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 317,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 317,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Identifier,
        lexeme: "output",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Identifier,
        lexeme: "stdout",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 319,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Identifier,
        lexeme: "d",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: String,
        lexeme: "'%d'",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 320,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: String,
        lexeme: "'%m'",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 321,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: String,
        lexeme: "'%Y'",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 322,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Identifier,
        lexeme: "ds",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: String,
        lexeme: "'%w'",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 323,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 323,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 324,
    },
    Token {
        kind: Identifier,
        lexeme: "h",
        computed_lexeme: None,
        line: 324,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 324,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 324,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 324,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 324,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 324,
    },
    Token {
        kind: String,
        lexeme: "'%H'",
        computed_lexeme: None,
        line: 324,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 324,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 325,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 325,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 325,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 325,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 325,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 325,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 325,
    },
    Token {
        kind: String,
        lexeme: "'%M'",
        computed_lexeme: None,
        line: 325,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 325,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 326,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 326,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 326,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 326,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 326,
    },
    Token {
        kind: Identifier,
        lexeme: "date",
        computed_lexeme: None,
        line: 326,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 326,
    },
    Token {
        kind: String,
        lexeme: "'%S'",
        computed_lexeme: None,
        line: 326,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 326,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: String,
        lexeme: "'test done on %2.2d/%2.2d/%d'",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "d",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "m",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 327,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: String,
        lexeme: "', at %2.2d:%2.2d:%2.2d\\n'",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Identifier,
        lexeme: "h",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 328,
    },
    Token {
        kind: Identifier,
        lexeme: "io",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: Identifier,
        lexeme: "write",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: String,
        lexeme: "'%s\\n'",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: Identifier,
        lexeme: "_VERSION",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 329,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 329,
    },
]
