---
source: src/main.rs
expression: scanned
input_file: test-data/lua5.2-tests/math.lua
---
[
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: String,
        lexeme: "\"testing numbers and math lib\"",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Number,
        lexeme: "0e12",
        computed_lexeme: Some(
            "0e12",
        ),
        line: 5,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 5,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Number,
        lexeme: ".0",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 5,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 5,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Number,
        lexeme: "0.",
        computed_lexeme: Some(
            "0.0",
        ),
        line: 5,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 5,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Number,
        lexeme: ".2e2",
        computed_lexeme: Some(
            "0.2e2",
        ),
        line: 5,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Number,
        lexeme: "20",
        computed_lexeme: Some(
            "20",
        ),
        line: 5,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Number,
        lexeme: "2.E-1",
        computed_lexeme: Some(
            "2.0e-1",
        ),
        line: 5,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Number,
        lexeme: "0.2",
        computed_lexeme: Some(
            "0.2",
        ),
        line: 5,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 5,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 7,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: String,
        lexeme: "\"2\"",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: String,
        lexeme: "\" 3e0 \"",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: String,
        lexeme: "\" 10  \"",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 9,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 9,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: String,
        lexeme: "\"2\"",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 9,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: String,
        lexeme: "\"10\"",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 9,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: String,
        lexeme: "'string'",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: String,
        lexeme: "'string'",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "type",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: String,
        lexeme: "'string'",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 10,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: String,
        lexeme: "\"2\"",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: String,
        lexeme: "\" 3e0 \"",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: String,
        lexeme: "\" 10  \"",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: String,
        lexeme: "\"  10 \"",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 11,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 12,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Number,
        lexeme: "08",
        computed_lexeme: Some(
            "08",
        ),
        line: 12,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 13,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 13,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 14,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 14,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 15,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 17,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 18,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 18,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 19,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 20,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "20",
        computed_lexeme: Some(
            "20",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "30",
        computed_lexeme: Some(
            "30",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "40",
        computed_lexeme: Some(
            "40",
        ),
        line: 20,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Number,
        lexeme: "50",
        computed_lexeme: Some(
            "50",
        ),
        line: 20,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 21,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 21,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 21,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 24,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "modf",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "3.5",
        computed_lexeme: Some(
            "3.5",
        ),
        line: 25,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 26,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 26,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 26,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Number,
        lexeme: "10e30",
        computed_lexeme: Some(
            "10e30",
        ),
        line: 27,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 27,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Number,
        lexeme: "10e30",
        computed_lexeme: Some(
            "10e30",
        ),
        line: 28,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 29,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: TripleDot,
        lexeme: "...",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Identifier,
        lexeme: "select",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: String,
        lexeme: "'#'",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: TripleDot,
        lexeme: "...",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 32,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: TripleDot,
        lexeme: "...",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: String,
        lexeme: "\"***\"",
        computed_lexeme: None,
        line: 35,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: String,
        lexeme: "\"2\"",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 41,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 41,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: String,
        lexeme: "\"2 \"",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 42,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 42,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: String,
        lexeme: "\" -2 \"",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 43,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 43,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: String,
        lexeme: "\" -0xa \"",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 44,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 44,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 44,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: String,
        lexeme: "'+0.01'",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 49,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: Number,
        lexeme: "100",
        computed_lexeme: Some(
            "100",
        ),
        line: 49,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: String,
        lexeme: "'+.01'",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: Number,
        lexeme: "0.01",
        computed_lexeme: Some(
            "0.01",
        ),
        line: 49,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 49,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: String,
        lexeme: "'.01'",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Number,
        lexeme: "0.01",
        computed_lexeme: Some(
            "0.01",
        ),
        line: 50,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: String,
        lexeme: "'-1.'",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 50,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 50,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: String,
        lexeme: "'+1.'",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 51,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: String,
        lexeme: "'+ 0.01'",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: String,
        lexeme: "'+.e1'",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: String,
        lexeme: "'1e'",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: String,
        lexeme: "'1.0e+'",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: String,
        lexeme: "'.'",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: String,
        lexeme: "'-012'",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Number,
        lexeme: "010",
        computed_lexeme: Some(
            "010",
        ),
        line: 55,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 55,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: String,
        lexeme: "'-1.2e2'",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Number,
        lexeme: "120",
        computed_lexeme: Some(
            "120",
        ),
        line: 56,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: String,
        lexeme: "\"0xffffffffffff\"",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 58,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 58,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Number,
        lexeme: "12",
        computed_lexeme: Some(
            "12",
        ),
        line: 58,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 58,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: String,
        lexeme: "\"0x\"",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: String,
        lexeme: "\"f\"",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Number,
        lexeme: "150",
        computed_lexeme: Some(
            "150",
        ),
        line: 59,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 59,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 59,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Number,
        lexeme: "150",
        computed_lexeme: Some(
            "150",
        ),
        line: 59,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 59,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: String,
        lexeme: "'0x3.'",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: String,
        lexeme: "'0'",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Number,
        lexeme: "100",
        computed_lexeme: Some(
            "100",
        ),
        line: 60,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 60,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: String,
        lexeme: "'0x0.'",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: String,
        lexeme: "'0'",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Number,
        lexeme: "150",
        computed_lexeme: Some(
            "150",
        ),
        line: 61,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: String,
        lexeme: "\"1\"",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 61,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 61,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Number,
        lexeme: "151",
        computed_lexeme: Some(
            "151",
        ),
        line: 61,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: String,
        lexeme: "'  001010  '",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 64,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 64,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: String,
        lexeme: "'  001010  '",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 65,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Number,
        lexeme: "001010",
        computed_lexeme: Some(
            "001010",
        ),
        line: 65,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: String,
        lexeme: "'  -1010  '",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 66,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 66,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: String,
        lexeme: "'10'",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 67,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 67,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: String,
        lexeme: "'  -10  '",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 68,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 68,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: String,
        lexeme: "'  +1Z  '",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 69,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 69,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Number,
        lexeme: "35",
        computed_lexeme: Some(
            "35",
        ),
        line: 69,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 69,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: String,
        lexeme: "'  -1z  '",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 70,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 70,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Number,
        lexeme: "35",
        computed_lexeme: Some(
            "35",
        ),
        line: 70,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: String,
        lexeme: "'-fFfa'",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 71,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 71,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 71,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 71,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 71,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 71,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: String,
        lexeme: "'1'",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Number,
        lexeme: "42",
        computed_lexeme: Some(
            "42",
        ),
        line: 72,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 72,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 72,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 72,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Number,
        lexeme: "42",
        computed_lexeme: Some(
            "42",
        ),
        line: 72,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: String,
        lexeme: "'1'",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Number,
        lexeme: "34",
        computed_lexeme: Some(
            "34",
        ),
        line: 73,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 73,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 73,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 73,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Number,
        lexeme: "34",
        computed_lexeme: Some(
            "34",
        ),
        line: 73,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 73,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: String,
        lexeme: "'ffffFFFF'",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 74,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 74,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 74,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 74,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 74,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: String,
        lexeme: "'0ffffFFFF'",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 75,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 75,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 75,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 75,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 75,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: String,
        lexeme: "'-0ffffffFFFF'",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 76,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 76,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 76,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Number,
        lexeme: "40",
        computed_lexeme: Some(
            "40",
        ),
        line: 76,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 77,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Number,
        lexeme: "36",
        computed_lexeme: Some(
            "36",
        ),
        line: 77,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: String,
        lexeme: "'\\t10000000000\\t'",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 78,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: String,
        lexeme: "'fFfa'",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 82,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: String,
        lexeme: "'099'",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Number,
        lexeme: "8",
        computed_lexeme: Some(
            "8",
        ),
        line: 83,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 83,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: String,
        lexeme: "'1\\0'",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 84,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 84,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: String,
        lexeme: "''",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Number,
        lexeme: "8",
        computed_lexeme: Some(
            "8",
        ),
        line: 85,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: String,
        lexeme: "'  '",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 86,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: String,
        lexeme: "'  '",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 87,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: String,
        lexeme: "'0xf'",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 88,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: String,
        lexeme: "'inf'",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: String,
        lexeme: "' INF '",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 91,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: String,
        lexeme: "'Nan'",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 92,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: String,
        lexeme: "'nan'",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 93,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: String,
        lexeme: "'  '",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: String,
        lexeme: "''",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: String,
        lexeme: "'1  a'",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: String,
        lexeme: "'1\\0'",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: String,
        lexeme: "'1 \\0'",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: String,
        lexeme: "'1\\0 '",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: String,
        lexeme: "'e1'",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 101,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: String,
        lexeme: "'e  1'",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 102,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: String,
        lexeme: "' 3.4.5 '",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: String,
        lexeme: "'0x'",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: String,
        lexeme: "'x'",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: String,
        lexeme: "'x3'",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 110,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: String,
        lexeme: "'00x2'",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: String,
        lexeme: "'0x 2'",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: String,
        lexeme: "'0 x2'",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: String,
        lexeme: "'23x'",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 114,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: String,
        lexeme: "'- 0xaa'",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 115,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Number,
        lexeme: "0x10",
        computed_lexeme: Some(
            "0x10",
        ),
        line: 120,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 120,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Number,
        lexeme: "0xfff",
        computed_lexeme: Some(
            "0xfff",
        ),
        line: 120,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 120,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Number,
        lexeme: "12",
        computed_lexeme: Some(
            "12",
        ),
        line: 120,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 120,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Number,
        lexeme: "0XFB",
        computed_lexeme: Some(
            "0XFB",
        ),
        line: 120,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Number,
        lexeme: "251",
        computed_lexeme: Some(
            "251",
        ),
        line: 120,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 120,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Number,
        lexeme: "0x0p12",
        computed_lexeme: Some(
            "0",
        ),
        line: 121,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 121,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Number,
        lexeme: "0x.0p-3",
        computed_lexeme: Some(
            "0",
        ),
        line: 121,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 121,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 121,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Number,
        lexeme: "0xFFFFFFFF",
        computed_lexeme: Some(
            "0xFFFFFFFF",
        ),
        line: 122,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 122,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 122,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 122,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 122,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: String,
        lexeme: "'+0x2'",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 123,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 123,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: String,
        lexeme: "'-0xaA'",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Number,
        lexeme: "170",
        computed_lexeme: Some(
            "170",
        ),
        line: 124,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 124,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: String,
        lexeme: "'-0xffFFFfff'",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 125,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "32",
        computed_lexeme: Some(
            "32",
        ),
        line: 125,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 125,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 125,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Number,
        lexeme: "0E+1",
        computed_lexeme: Some(
            "0e+1",
        ),
        line: 128,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 128,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Number,
        lexeme: "0xE",
        computed_lexeme: Some(
            "0xE",
        ),
        line: 128,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 128,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Number,
        lexeme: "15",
        computed_lexeme: Some(
            "15",
        ),
        line: 128,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Number,
        lexeme: "0xe",
        computed_lexeme: Some(
            "0xe",
        ),
        line: 128,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 128,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Number,
        lexeme: "13",
        computed_lexeme: Some(
            "13",
        ),
        line: 128,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 128,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: String,
        lexeme: "'  0x2.5  '",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: Number,
        lexeme: "0x25",
        computed_lexeme: Some(
            "0x25",
        ),
        line: 133,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 133,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 133,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: String,
        lexeme: "'  -0x2.5  '",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: Number,
        lexeme: "0x25",
        computed_lexeme: Some(
            "0x25",
        ),
        line: 134,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 134,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 134,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: String,
        lexeme: "'  +0x0.51p+8  '",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Number,
        lexeme: "0x51",
        computed_lexeme: Some(
            "0x51",
        ),
        line: 135,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 135,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: String,
        lexeme: "'0x0.51p'",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 136,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: String,
        lexeme: "'0x5p+-2'",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 137,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Number,
        lexeme: "0x.FfffFFFF",
        computed_lexeme: Some(
            "0.9999999997671694",
        ),
        line: 138,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 138,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: String,
        lexeme: "'0x.00000001'",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 138,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: String,
        lexeme: "'0xA.a'",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 139,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 139,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 139,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Number,
        lexeme: "16",
        computed_lexeme: Some(
            "16",
        ),
        line: 139,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 139,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: Number,
        lexeme: "0xa.aP4",
        computed_lexeme: Some(
            "170",
        ),
        line: 140,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: Number,
        lexeme: "0XAA",
        computed_lexeme: Some(
            "0XAA",
        ),
        line: 140,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 140,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Number,
        lexeme: "0x4P-2",
        computed_lexeme: Some(
            "1",
        ),
        line: 141,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 141,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 141,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Number,
        lexeme: "0x1.1",
        computed_lexeme: Some(
            "1.0625",
        ),
        line: 142,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: String,
        lexeme: "'0x1.'",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: String,
        lexeme: "'+0x.1'",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 142,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 145,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Number,
        lexeme: "1.",
        computed_lexeme: Some(
            "1.0",
        ),
        line: 145,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Number,
        lexeme: ".1",
        computed_lexeme: Some(
            "0.1",
        ),
        line: 145,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 145,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Number,
        lexeme: "100.0",
        computed_lexeme: Some(
            "100.0",
        ),
        line: 146,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Number,
        lexeme: "1E2",
        computed_lexeme: Some(
            "1e2",
        ),
        line: 146,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Number,
        lexeme: ".01",
        computed_lexeme: Some(
            "0.01",
        ),
        line: 146,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Number,
        lexeme: "1e-2",
        computed_lexeme: Some(
            "1e-2",
        ),
        line: 146,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 146,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Number,
        lexeme: "1111111111111111",
        computed_lexeme: Some(
            "1111111111111111",
        ),
        line: 147,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Number,
        lexeme: "1111111111111110",
        computed_lexeme: Some(
            "1111111111111110",
        ),
        line: 147,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Number,
        lexeme: "1000.00e-03",
        computed_lexeme: Some(
            "1000.00e-03",
        ),
        line: 147,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 147,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Number,
        lexeme: "1.1",
        computed_lexeme: Some(
            "1.1",
        ),
        line: 149,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: String,
        lexeme: "'1.'",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: String,
        lexeme: "'.1'",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 149,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: String,
        lexeme: "'1111111111111111'",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: String,
        lexeme: "'1111111111111110'",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: String,
        lexeme: "\"  +0.001e+3 \\n\\t\"",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 150,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: Identifier,
        lexeme: "limit",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 152,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Identifier,
        lexeme: "limit",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Identifier,
        lexeme: "limit",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Number,
        lexeme: "10E-10",
        computed_lexeme: Some(
            "10e-10",
        ),
        line: 153,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 153,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "abs",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: Identifier,
        lexeme: "limit",
        computed_lexeme: None,
        line: 154,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 155,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: Number,
        lexeme: "0.1e-30",
        computed_lexeme: Some(
            "0.1e-30",
        ),
        line: 157,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: Number,
        lexeme: "0.9E-31",
        computed_lexeme: Some(
            "0.9e-31",
        ),
        line: 157,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: Number,
        lexeme: "0.9E30",
        computed_lexeme: Some(
            "0.9e30",
        ),
        line: 157,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: Number,
        lexeme: "0.1e31",
        computed_lexeme: Some(
            "0.1e31",
        ),
        line: 157,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Number,
        lexeme: "0.123456",
        computed_lexeme: Some(
            "0.123456",
        ),
        line: 159,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Number,
        lexeme: "0.123455",
        computed_lexeme: Some(
            "0.123455",
        ),
        line: 159,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: String,
        lexeme: "'+1.23E18'",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Number,
        lexeme: "1.23",
        computed_lexeme: Some(
            "1.23",
        ),
        line: 161,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 161,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Number,
        lexeme: "18",
        computed_lexeme: Some(
            "18",
        ),
        line: 161,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 164,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 164,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 164,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 164,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 164,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 164,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 166,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 166,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 166,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 166,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 166,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 166,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 167,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 168,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 168,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 168,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 168,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 168,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 168,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 168,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 169,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 170,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 170,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 170,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 170,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 170,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 170,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: String,
        lexeme: "'b'",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 171,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 174,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 174,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 174,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 174,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 175,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 175,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 175,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 175,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 176,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 176,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 176,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Number,
        lexeme: "0.001",
        computed_lexeme: Some(
            "0.001",
        ),
        line: 177,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Number,
        lexeme: "3.141",
        computed_lexeme: Some(
            "3.141",
        ),
        line: 177,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 177,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 179,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 179,
    },
    Token {
        kind: Identifier,
        lexeme: "testbit",
        computed_lexeme: None,
        line: 179,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 179,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 179,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 179,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 179,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 179,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 180,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 180,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 180,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 180,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 181,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "sin",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Number,
        lexeme: "9.8",
        computed_lexeme: Some(
            "9.8",
        ),
        line: 183,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 183,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "cos",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Number,
        lexeme: "9.8",
        computed_lexeme: Some(
            "9.8",
        ),
        line: 183,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 183,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 183,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 183,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "tan",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 184,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 184,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "sin",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "cos",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "atan",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Number,
        lexeme: "4",
        computed_lexeme: Some(
            "4",
        ),
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "acos",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "asin",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 187,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 187,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "deg",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 188,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Number,
        lexeme: "90",
        computed_lexeme: Some(
            "90",
        ),
        line: 188,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "rad",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Number,
        lexeme: "90",
        computed_lexeme: Some(
            "90",
        ),
        line: 188,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 188,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Identifier,
        lexeme: "abs",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 189,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 189,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 189,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "atan2",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 190,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 190,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 190,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 190,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Identifier,
        lexeme: "ceil",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Number,
        lexeme: "4.5",
        computed_lexeme: Some(
            "4.5",
        ),
        line: 191,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Number,
        lexeme: "5.0",
        computed_lexeme: Some(
            "5.0",
        ),
        line: 191,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 191,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "floor",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Number,
        lexeme: "4.5",
        computed_lexeme: Some(
            "4.5",
        ),
        line: 192,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Number,
        lexeme: "4.0",
        computed_lexeme: Some(
            "4.0",
        ),
        line: 192,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "fmod",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 193,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 193,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 193,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "sqrt",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 194,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Caret,
        lexeme: "^",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 194,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 194,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 194,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 195,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 195,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 195,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 195,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 196,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 196,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 196,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "log",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Number,
        lexeme: "9",
        computed_lexeme: Some(
            "9",
        ),
        line: 197,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Number,
        lexeme: "3",
        computed_lexeme: Some(
            "3",
        ),
        line: 197,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 197,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 197,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "exp",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 198,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 198,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "sin",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 199,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "sin",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 199,
    },
    Token {
        kind: Percent,
        lexeme: "%",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 199,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "v",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "e",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "frexp",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 200,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "ldexp",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "v",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "e",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "pi",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "tanh",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Number,
        lexeme: "3.5",
        computed_lexeme: Some(
            "3.5",
        ),
        line: 203,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "sinh",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Number,
        lexeme: "3.5",
        computed_lexeme: Some(
            "3.5",
        ),
        line: 203,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "cosh",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Number,
        lexeme: "3.5",
        computed_lexeme: Some(
            "3.5",
        ),
        line: 203,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 203,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: String,
        lexeme: "' 1.3e-2 '",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Number,
        lexeme: "1.3e-2",
        computed_lexeme: Some(
            "1.3e-2",
        ),
        line: 205,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 205,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: String,
        lexeme: "' -1.00000000000001 '",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Number,
        lexeme: "1.00000000000001",
        computed_lexeme: Some(
            "1.00000000000001",
        ),
        line: 206,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 206,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Number,
        lexeme: "8388609",
        computed_lexeme: Some(
            "8388609",
        ),
        line: 210,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Number,
        lexeme: "8388609",
        computed_lexeme: Some(
            "8388609",
        ),
        line: 210,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 210,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 210,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Number,
        lexeme: "8388608",
        computed_lexeme: Some(
            "8388608",
        ),
        line: 211,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Number,
        lexeme: "8388608",
        computed_lexeme: Some(
            "8388608",
        ),
        line: 211,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 211,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 211,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Number,
        lexeme: "8388607",
        computed_lexeme: Some(
            "8388607",
        ),
        line: 212,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Number,
        lexeme: "8388607",
        computed_lexeme: Some(
            "8388607",
        ),
        line: 212,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 212,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 212,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: String,
        lexeme: "'10'",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: String,
        lexeme: "'20'",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Number,
        lexeme: "200",
        computed_lexeme: Some(
            "200",
        ),
        line: 217,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Number,
        lexeme: "30",
        computed_lexeme: Some(
            "30",
        ),
        line: 217,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 217,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Number,
        lexeme: "0.5",
        computed_lexeme: Some(
            "0.5",
        ),
        line: 217,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Number,
        lexeme: "20",
        computed_lexeme: Some(
            "20",
        ),
        line: 217,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: String,
        lexeme: "'10'",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: String,
        lexeme: "'20'",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 221,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 221,
    },
    Token {
        kind: Identifier,
        lexeme: "_port",
        computed_lexeme: None,
        line: 221,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 221,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: String,
        lexeme: "\"testing -0 and NaN\"",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 223,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 223,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 223,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 225,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 225,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 225,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 225,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 226,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 227,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 227,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 227,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "inf",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Star,
        lexeme: "*",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Number,
        lexeme: "2",
        computed_lexeme: Some(
            "2",
        ),
        line: 228,
    },
    Token {
        kind: Plus,
        lexeme: "+",
        computed_lexeme: None,
        line: 228,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 228,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 229,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Identifier,
        lexeme: "inf",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 229,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Identifier,
        lexeme: "inf",
        computed_lexeme: None,
        line: 229,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 231,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "mz",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 231,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 231,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 231,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "z",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "inf",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "inf",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: GreaterThan,
        lexeme: ">",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: GreaterThanOrEqual,
        lexeme: ">=",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 238,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: LessThan,
        lexeme: "<",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 238,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN1",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 239,
    },
    Token {
        kind: Slash,
        lexeme: "/",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN1",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN1",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN1",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 242,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 244,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 244,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "pcall",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 245,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 245,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Identifier,
        lexeme: "NaN",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 246,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "a1",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "a2",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "a3",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "a4",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "a5",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 249,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 249,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: String,
        lexeme: "\"\\0\\0\\0\\0\\0\\0\\0\\0\"",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 249,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: String,
        lexeme: "\"\\0\\0\\0\\0\\0\\0\\0\\0\"",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "a1",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "a2",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "a2",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "a4",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "a1",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "a3",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: Identifier,
        lexeme: "a3",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: Identifier,
        lexeme: "a5",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 251,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 252,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Identifier,
        lexeme: "_port",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: String,
        lexeme: "\"testing 'math.random'\"",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Identifier,
        lexeme: "randomseed",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 257,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 257,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Identifier,
        lexeme: "x1",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Identifier,
        lexeme: "x2",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 259,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "Max",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 260,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Identifier,
        lexeme: "Min",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: Identifier,
        lexeme: "huge",
        computed_lexeme: None,
        line: 261,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 262,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Number,
        lexeme: "20000",
        computed_lexeme: Some(
            "20000",
        ),
        line: 262,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 262,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "table",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "unpack",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "p",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 263,
    },
    Token {
        kind: Identifier,
        lexeme: "Max",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "max",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "Max",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 264,
    },
    Token {
        kind: Identifier,
        lexeme: "Min",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Identifier,
        lexeme: "min",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Identifier,
        lexeme: "Min",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 265,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "Max",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "x2",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Number,
        lexeme: "0.001",
        computed_lexeme: Some(
            "0.001",
        ),
        line: 266,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "eq",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "Min",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Identifier,
        lexeme: "x1",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Number,
        lexeme: "0.001",
        computed_lexeme: Some(
            "0.001",
        ),
        line: 266,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 266,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 267,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 268,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 270,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 270,
    },
    Token {
        kind: False,
        lexeme: "false",
        computed_lexeme: None,
        line: 270,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 270,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Identifier,
        lexeme: "x1",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Identifier,
        lexeme: "Min",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Identifier,
        lexeme: "Max",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: Identifier,
        lexeme: "x2",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 271,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 272,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 274,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 274,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 274,
    },
    Token {
        kind: Identifier,
        lexeme: "aux",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 275,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 275,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 275,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: Number,
        lexeme: "0",
        computed_lexeme: Some(
            "0",
        ),
        line: 275,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 275,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 276,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 278,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Number,
        lexeme: "10",
        computed_lexeme: Some(
            "10",
        ),
        line: 278,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 278,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Identifier,
        lexeme: "math",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Identifier,
        lexeme: "random",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 279,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 279,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Number,
        lexeme: "1",
        computed_lexeme: Some(
            "1",
        ),
        line: 280,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Identifier,
        lexeme: "t",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: LessThanOrEqual,
        lexeme: "<=",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: Number,
        lexeme: "5",
        computed_lexeme: Some(
            "5",
        ),
        line: 280,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 280,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 281,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: String,
        lexeme: "'OK'",
        computed_lexeme: None,
        line: 284,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 284,
    },
]
