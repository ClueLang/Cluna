---
source: src/main.rs
expression: scanned
input_file: test-data/lua5.2-tests/literals.lua
---
[
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: String,
        lexeme: "'testing scanner'",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 1,
    },
    Token {
        kind: Identifier,
        lexeme: "debug",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Identifier,
        lexeme: "require",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: String,
        lexeme: "\"debug\"",
        computed_lexeme: None,
        line: 3,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "dostring",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Return,
        lexeme: "return",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 6,
    },
    Token {
        kind: Identifier,
        lexeme: "dostring",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: String,
        lexeme: "\"x \\v\\f = \\t\\r 'a\\0a' \\v\\f\\f\"",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 8,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: String,
        lexeme: "'a\\0a'",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Number,
        lexeme: " 3",
        computed_lexeme: Some(
            "3",
        ),
        line: 9,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 9,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: String,
        lexeme: "'\\n\\\"\\'\\\\'",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 12,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\n\n\"'\\]]",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 14,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Identifier,
        lexeme: "find",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: String,
        lexeme: "\"\\a\\b\\f\\n\\r\\t\\v\"",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: String,
        lexeme: "\"^%c%c%c%c%c%c%c$\"",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 16,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: String,
        lexeme: "\"\\09912\"",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: String,
        lexeme: "'c12'",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 19,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: String,
        lexeme: "\"\\99ab\"",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: String,
        lexeme: "'cab'",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 20,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: String,
        lexeme: "\"\\099\"",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: String,
        lexeme: "'\\99'",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 21,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: String,
        lexeme: "\"\\099\\n\"",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: String,
        lexeme: "'c\\10'",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 22,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: String,
        lexeme: "'\\0\\0\\0alo'",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: String,
        lexeme: "'\\0'",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: String,
        lexeme: "'\\0\\0'",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: String,
        lexeme: "'alo'",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 23,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "(010",
        computed_lexeme: Some(
            "010",
        ),
        line: 25,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: " 020",
        computed_lexeme: Some(
            "020",
        ),
        line: 25,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Number,
        lexeme: "-030",
        computed_lexeme: Some(
            "030",
        ),
        line: 25,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: String,
        lexeme: "\"1020-30\"",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 25,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: String,
        lexeme: "\"\\x00\\x05\\x10\\x1f\\x3C\\xfF\\xe8\"",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: String,
        lexeme: "\"\\0\\5\\16\\31\\60\\255\\232\"",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 28,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Identifier,
        lexeme: "lexstring",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 30,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: String,
        lexeme: "'return '",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: String,
        lexeme: "', debug.getinfo(1).currentline'",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 31,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Identifier,
        lexeme: "f",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 32,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Identifier,
        lexeme: "l",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 33,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 34,
    },
    Token {
        kind: Identifier,
        lexeme: "lexstring",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: String,
        lexeme: "\"'abc\\\\z  \\n   efg'\"",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: String,
        lexeme: "\"abcefg\"",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Number,
        lexeme: " 2",
        computed_lexeme: Some(
            "2",
        ),
        line: 36,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 36,
    },
    Token {
        kind: Identifier,
        lexeme: "lexstring",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: String,
        lexeme: "\"'abc\\\\z  \\n\\n\\n'\"",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: String,
        lexeme: "\"abc\"",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Number,
        lexeme: " 4",
        computed_lexeme: Some(
            "4",
        ),
        line: 37,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 37,
    },
    Token {
        kind: Identifier,
        lexeme: "lexstring",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: String,
        lexeme: "\"'\\\\z  \\n\\t\\f\\v\\n'\"",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Number,
        lexeme: " 3",
        computed_lexeme: Some(
            "3",
        ),
        line: 38,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 38,
    },
    Token {
        kind: Identifier,
        lexeme: "lexstring",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: String,
        lexeme: "\"[[\\nalo\\nalo\\n\\n]]\"",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: String,
        lexeme: "\"alo\\nalo\\n\\n\"",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: Number,
        lexeme: " 5",
        computed_lexeme: Some(
            "5",
        ),
        line: 39,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 39,
    },
    Token {
        kind: Identifier,
        lexeme: "lexstring",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: String,
        lexeme: "\"[[\\nalo\\ralo\\n\\n]]\"",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: String,
        lexeme: "\"alo\\nalo\\n\\n\"",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Number,
        lexeme: " 5",
        computed_lexeme: Some(
            "5",
        ),
        line: 40,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 40,
    },
    Token {
        kind: Identifier,
        lexeme: "lexstring",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: String,
        lexeme: "\"[[\\nalo\\ralo\\r\\n]]\"",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: String,
        lexeme: "\"alo\\nalo\\n\"",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Number,
        lexeme: " 4",
        computed_lexeme: Some(
            "4",
        ),
        line: 41,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 41,
    },
    Token {
        kind: Identifier,
        lexeme: "lexstring",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: String,
        lexeme: "\"[[\\ralo\\n\\ralo\\r\\n]]\"",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: String,
        lexeme: "\"alo\\nalo\\n\"",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Number,
        lexeme: " 4",
        computed_lexeme: Some(
            "4",
        ),
        line: 42,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 42,
    },
    Token {
        kind: Identifier,
        lexeme: "lexstring",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: String,
        lexeme: "\"[[alo]\\n]alo]]\"",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: String,
        lexeme: "\"alo]\\n]alo\"",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Number,
        lexeme: " 2",
        computed_lexeme: Some(
            "2",
        ),
        line: 43,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 43,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 45,
    },
    Token {
        kind: String,
        lexeme: "\"abc\\z\n        def\\z\n        ghi\\z\n       \"",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: String,
        lexeme: "'abcdefghi'",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 48,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Identifier,
        lexeme: "err",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 51,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Identifier,
        lexeme: "st",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Identifier,
        lexeme: "msg",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: String,
        lexeme: "'return '",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 52,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "err",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: String,
        lexeme: "'<eof>'",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "err",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: String,
        lexeme: "\"'\"",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "err",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: String,
        lexeme: "\"'\"",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 53,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "st",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "find",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "msg",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: String,
        lexeme: "\"near \"",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Identifier,
        lexeme: "err",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: Number,
        lexeme: " 1",
        computed_lexeme: Some(
            "1",
        ),
        line: 54,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: True,
        lexeme: "true",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 54,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 55,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"abc\\x\"]]",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\x\"]]",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 56,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 57,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 57,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"abc\\x]]",
        computed_lexeme: None,
        line: 57,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 57,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\x]]",
        computed_lexeme: None,
        line: 57,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 57,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\x]]",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\x]]",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 58,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\x5\"]]",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\x5\"]]",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 59,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\x5]]",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\x5]]",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 60,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\xr\"]]",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\xr]]",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 61,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\xr]]",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\xr]]",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 62,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\x.]]",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\x.]]",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 63,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\x8%\"]]",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\x8%]]",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 64,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\xAG]]",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\xAG]]",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 65,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\g\"]]",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\g]]",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 66,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\g]]",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\g]]",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 67,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\.\"]]",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\.]]",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 68,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"\\999\"]]",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\999]]",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 70,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"xyz\\300\"]]",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\300]]",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 71,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\"   \\256\"]]",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\\256]]",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 72,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: String,
        lexeme: "\"[=[alo]]\"",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: String,
        lexeme: "\"<eof>\"",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 76,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: String,
        lexeme: "\"[=[alo]=\"",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: String,
        lexeme: "\"<eof>\"",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 77,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: String,
        lexeme: "\"[=[alo]\"",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: String,
        lexeme: "\"<eof>\"",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 78,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: String,
        lexeme: "\"'alo\"",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: String,
        lexeme: "\"<eof>\"",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 79,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: String,
        lexeme: "\"'alo \\\\z  \\n\\n\"",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: String,
        lexeme: "\"<eof>\"",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 80,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: String,
        lexeme: "\"'alo \\\\z\"",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: String,
        lexeme: "\"<eof>\"",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 81,
    },
    Token {
        kind: Identifier,
        lexeme: "lexerror",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: MultilineString,
        lexeme: "[['alo \\98]]",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: String,
        lexeme: "\"<eof>\"",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 82,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Number,
        lexeme: " 0",
        computed_lexeme: Some(
            "0",
        ),
        line: 85,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Number,
        lexeme: " 255",
        computed_lexeme: Some(
            "255",
        ),
        line: 85,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 85,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "char",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "i",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 86,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "find",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: String,
        lexeme: "\"[a-zA-Z_]\"",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: String,
        lexeme: "\"=1\"",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 87,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "find",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: String,
        lexeme: "\"[a-zA-Z_0-9]\"",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 88,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: String,
        lexeme: "\"a\"",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: String,
        lexeme: "\"1 = 1\"",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 89,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 90,
    },
    Token {
        kind: Identifier,
        lexeme: "var",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "rep",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: String,
        lexeme: "'a'",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Number,
        lexeme: " 15000",
        computed_lexeme: Some(
            "15000",
        ),
        line: 95,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 95,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: String,
        lexeme: "\"%s = 5\"",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "var",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 96,
    },
    Token {
        kind: Identifier,
        lexeme: "dostring",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 97,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: LeftBracket,
        lexeme: "[",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "var",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: RightBracket,
        lexeme: "]",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Number,
        lexeme: " 5",
        computed_lexeme: Some(
            "5",
        ),
        line: 98,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 98,
    },
    Token {
        kind: Identifier,
        lexeme: "var",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 99,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: String,
        lexeme: "'+'",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 100,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\\t\"",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 103,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\n\n\t]]",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 105,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 106,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\n\n $debug]]",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: String,
        lexeme: "\"\\n $debug\"",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 108,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[ [ ]]",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: NotEquals,
        lexeme: "~=",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[ ] ]]",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 109,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: String,
        lexeme: "\"001234567890123456789012345678901234567891234567890123456789012345678901234567890012345678901234567890123456789012345678912345678901234567890123456789012345678900123456789012345678901234567890123456789123456789012345678901234567890123456789001234567890123456789012345678901234567891234567890123456789012345678901234567890012345678901234567890123456789012345678912345678901234567890123456789012345678900123456789012345678901234567890123456789123456789012345678901234567890123456789001234567890123456789012345678901234567891234567890123456789012345678901234567890012345678901234567890123456789012345678912345678901234567890123456789012345678900123456789012345678901234567890123456789123456789012345678901234567890123456789001234567890123456789012345678901234567891234567890123456789012345678901234567890012345678901234567890123456789012345678912345678901234567890123456789012345678900123456789012345678901234567890123456789123456789012345678901234567890123456789\"",
        computed_lexeme: None,
        line: 111,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Number,
        lexeme: " 960",
        computed_lexeme: Some(
            "960",
        ),
        line: 112,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 112,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 113,
    },
    Token {
        kind: MultilineString,
        lexeme: "[=[\nprint('+')\n\na1 = [[\"isto e' um string com várias 'aspas'\"]]\na2 = \"'aspas'\"\n\nassert(string.find(a1, a2) == 31)\nprint('+')\n\na1 = [==[temp = [[um valor qualquer]]; ]==]\nassert(load(a1))()\nassert(temp == 'um valor qualquer')\n-- long strings --\nb = \"001234567890123456789012345678901234567891234567890123456789012345678901234567890012345678901234567890123456789012345678912345678901234567890123456789012345678900123456789012345678901234567890123456789123456789012345678901234567890123456789001234567890123456789012345678901234567891234567890123456789012345678901234567890012345678901234567890123456789012345678912345678901234567890123456789012345678900123456789012345678901234567890123456789123456789012345678901234567890123456789001234567890123456789012345678901234567891234567890123456789012345678901234567890012345678901234567890123456789012345678912345678901234567890123456789012345678900123456789012345678901234567890123456789123456789012345678901234567890123456789001234567890123456789012345678901234567891234567890123456789012345678901234567890012345678901234567890123456789012345678912345678901234567890123456789012345678900123456789012345678901234567890123456789123456789012345678901234567890123456789\"\nassert(string.len(b) == 960)\nprint('+')\n\na = [[00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n00123456789012345678901234567890123456789123456789012345678901234567890123456789\n]]\nassert(string.len(a) == 1863)\nassert(string.sub(a, 1, 40) == string.sub(b, 1, 40))\nx = 1\n]=]",
        computed_lexeme: None,
        line: 157,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: String,
        lexeme: "'+'",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 159,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 160,
    },
    Token {
        kind: Identifier,
        lexeme: "dostring",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 161,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 162,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 164,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 165,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 166,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 170,
    },
    Token {
        kind: MultilineString,
        lexeme: "[[\na = 1        -- a comment\nb = 2\n\n\nx = [=[\nhi\n]=]\ny = \"\\\nhello\\r\\n\\\n\"\nreturn debug.getinfo(1).currentline\n]]",
        computed_lexeme: None,
        line: 182,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Identifier,
        lexeme: "pairs",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\"",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: String,
        lexeme: "\"\\r\"",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\\r\"",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: String,
        lexeme: "\"\\r\\n\"",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 184,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "nn",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "gsub",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\"",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 185,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "dostring",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "prog",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "nn",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 186,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: String,
        lexeme: "\"hi\\n\"",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "_G",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: Identifier,
        lexeme: "y",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: String,
        lexeme: "\"\\nhello\\r\\n\\n\"",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 187,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 188,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: MultilineString,
        lexeme: "[==[]=]==]",
        computed_lexeme: None,
        line: 192,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: String,
        lexeme: "\"]=\"",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 193,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: MultilineString,
        lexeme: "[==[[===[[=[]]=][====[]]===]===]==]",
        computed_lexeme: None,
        line: 195,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: String,
        lexeme: "\"[===[[=[]]=][====[]]===]===\"",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 196,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: MultilineString,
        lexeme: "[====[[===[[=[]]=][====[]]===]===]====]",
        computed_lexeme: None,
        line: 198,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: String,
        lexeme: "\"[===[[=[]]=][====[]]===]===\"",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 199,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: MultilineString,
        lexeme: "[=[]]]]]]]]]=]",
        computed_lexeme: None,
        line: 201,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: String,
        lexeme: "\"]]]]]]]]\"",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 202,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: LeftBrace,
        lexeme: "{",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: String,
        lexeme: "\"=\"",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: String,
        lexeme: "\"[\"",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: String,
        lexeme: "\"]\"",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: String,
        lexeme: "\"\\n\"",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: RightBrace,
        lexeme: "}",
        computed_lexeme: None,
        line: 213,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 214,
    },
    Token {
        kind: Number,
        lexeme: " 4",
        computed_lexeme: Some(
            "4",
        ),
        line: 214,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Identifier,
        lexeme: "gen",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 215,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Number,
        lexeme: "=0",
        computed_lexeme: Some(
            "0",
        ),
        line: 216,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "coroutine",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "yield",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 216,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 217,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "_",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "pairs",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "x",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 218,
    },
    Token {
        kind: Identifier,
        lexeme: "gen",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Identifier,
        lexeme: "n",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Minus,
        lexeme: "-",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: Number,
        lexeme: "-1",
        computed_lexeme: Some(
            "1",
        ),
        line: 219,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 219,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 220,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 221,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 222,
    },
    Token {
        kind: For,
        lexeme: "for",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: In,
        lexeme: "in",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Identifier,
        lexeme: "coroutine",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Identifier,
        lexeme: "wrap",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Function,
        lexeme: "function",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Identifier,
        lexeme: "gen",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: String,
        lexeme: "\"\"",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Identifier,
        lexeme: "len",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Do,
        lexeme: "do",
        computed_lexeme: None,
        line: 224,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: String,
        lexeme: "\"return [====[\\n\"",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: DoubleDot,
        lexeme: "..",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: String,
        lexeme: "\"]====]\"",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 225,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 226,
    },
    Token {
        kind: If,
        lexeme: "if",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "setlocale",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: String,
        lexeme: "\"pt_BR\"",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "setlocale",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: String,
        lexeme: "\"ptb\"",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Then,
        lexeme: "then",
        computed_lexeme: None,
        line: 230,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: String,
        lexeme: "\"á = 3\"",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 231,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: String,
        lexeme: "\"a = (3,4)\"",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 232,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: String,
        lexeme: "\"3,4\"",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Number,
        lexeme: " 3.4",
        computed_lexeme: Some(
            "3.4",
        ),
        line: 233,
    },
    Token {
        kind: And,
        lexeme: "and",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "tonumber",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: String,
        lexeme: "\"3.4\"",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Nil,
        lexeme: "nil",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 233,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: String,
        lexeme: "\"return 3.4\"",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Number,
        lexeme: " 3.4",
        computed_lexeme: Some(
            "3.4",
        ),
        line: 234,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 234,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: String,
        lexeme: "\"return .4,3\"",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Number,
        lexeme: " .4",
        computed_lexeme: Some(
            "0.4",
        ),
        line: 235,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 235,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: String,
        lexeme: "\"return 4.\"",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Number,
        lexeme: " 4.",
        computed_lexeme: Some(
            "4.",
        ),
        line: 236,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 236,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: String,
        lexeme: "\"return 4.+.5\"",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Number,
        lexeme: " 4.5",
        computed_lexeme: Some(
            "4.5",
        ),
        line: 237,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 237,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "a",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: String,
        lexeme: "\"return 4.5.\"",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 238,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "find",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "b",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: String,
        lexeme: "\"'4%.5%.'\"",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 239,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "os",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Identifier,
        lexeme: "setlocale",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: String,
        lexeme: "\"C\"",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 240,
    },
    Token {
        kind: Else,
        lexeme: "else",
        computed_lexeme: None,
        line: 241,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "Message",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Or,
        lexeme: "or",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 242,
    },
    Token {
        kind: String,
        lexeme: "'\\a\\n >>> pt_BR locale not available: skipping decimal point tests <<<\\n\\a'",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 243,
    },
    Token {
        kind: End,
        lexeme: "end",
        computed_lexeme: None,
        line: 244,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: String,
        lexeme: "\"a string with \\r and \\n and \\r\\n and \\n\\r\"",
        computed_lexeme: None,
        line: 248,
    },
    Token {
        kind: Local,
        lexeme: "local",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Equals,
        lexeme: "=",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "string",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Dot,
        lexeme: ".",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "format",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: String,
        lexeme: "\"return %q\"",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Comma,
        lexeme: ",",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 249,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "c",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: DoubleEquals,
        lexeme: "==",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "s",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 250,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: String,
        lexeme: "\"a = 'non-ending string\"",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 253,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: String,
        lexeme: "\"a = 'non-ending string\\n'\"",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 254,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: String,
        lexeme: "\"a = '\\\\345'\"",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 255,
    },
    Token {
        kind: Identifier,
        lexeme: "assert",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Not,
        lexeme: "not",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Identifier,
        lexeme: "load",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: String,
        lexeme: "\"a = [=x]\"",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 256,
    },
    Token {
        kind: Identifier,
        lexeme: "print",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: LeftParen,
        lexeme: "(",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: String,
        lexeme: "'OK'",
        computed_lexeme: None,
        line: 258,
    },
    Token {
        kind: RightParen,
        lexeme: ")",
        computed_lexeme: None,
        line: 258,
    },
]
